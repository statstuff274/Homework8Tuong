[
  {
    "objectID": "Homework8Tuong.html",
    "href": "Homework8Tuong.html",
    "title": "Week 8 - Basic Modeling Practice",
    "section": "",
    "text": "The purpose of this assignment is to create an EDA, exploratory data analysis, document for a data set about Seoul Bikes. We do this in order to better understand our data. The document will go through the following:\n\n\nChecking the data.\nSplitting the data.\nFitting MLR models.\n\n\nNote: Items are numbered for ease of grading; regardless, the document is still to be read in narrative form.\n\n\n\n\nStaring off, we’re going to install and load the necessary packages to create the EDA. Then we’ll read in the data.\n\n\n# Installed packages\n# install.packages(\"tidyverse\")\n# install.packages(\"tidymodels\") # For use of tidymodel functions\n# install.packages(\"lubridate\")\n# install.packages(\"janitor\")\n\n\n# Loading in libraries\nlibrary(tidyverse)\nlibrary(tidymodels)  \nlibrary(lubridate)\nlibrary(janitor)\nlibrary(readr)  \n\n\n# Read in data\nbikes &lt;- readr::read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\", locale = locale(encoding = \"latin1\"))\nbikes\n\n# A tibble: 8,760 × 14\n   Date       `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n   &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 01/12/2017                 254     0              -5.2            37\n 2 01/12/2017                 204     1              -5.5            38\n 3 01/12/2017                 173     2              -6              39\n 4 01/12/2017                 107     3              -6.2            40\n 5 01/12/2017                  78     4              -6              36\n 6 01/12/2017                 100     5              -6.4            37\n 7 01/12/2017                 181     6              -6.6            35\n 8 01/12/2017                 460     7              -7.4            38\n 9 01/12/2017                 930     8              -7.6            37\n10 01/12/2017                 490     9              -6.5            27\n# ℹ 8,750 more rows\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(°C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;chr&gt;, Holiday &lt;chr&gt;,\n#   `Functioning Day` &lt;chr&gt;\n\n\n\n\nNext we’re going to check for missingness within our data set. As seen below, there are no columns missing any values or data, so we can move forward with continuing to check the data.\n\n\n\n# Checked for missingness - to see if there are any missing values in the data set.\nmissingnesscheck &lt;- is.na(bikes) %&gt;% colSums()\nmissingnesscheck\n\n                     Date         Rented Bike Count                      Hour \n                        0                         0                         0 \n          Temperature(°C)               Humidity(%)          Wind speed (m/s) \n                        0                         0                         0 \n         Visibility (10m) Dew point temperature(°C)   Solar Radiation (MJ/m2) \n                        0                         0                         0 \n             Rainfall(mm)             Snowfall (cm)                   Seasons \n                        0                         0                         0 \n                  Holiday           Functioning Day \n                        0                         0 \n\n\n\n\nNow we’ll check the column types and their values to ensure it makes sense. We’ll do a basic summary of statistics for numeric columns and then check for the unique values of the categorical variables.\n\nUsing the str function, when checking for the column types and values, it does indicate that the variables contain the correct column types and values accordingly. There are a total of 14 variables: 10 are numeric types (Rented Bike Count, Hour, Temperature, Humidity, Wind speed, Visibility, Dew point temperature, Solar Radiation, Rainfall, Snowfall) and 4 are character types (Date, Seasons, Holidays, Functioning Day).\nUsing the summary function we selected numeric columns to create summary statistics for, which include the minimum, 1st quartile, median, mean, 3rd quartile, and maximum. These summary statistics give us some insight regarding weather conditions and total bike rentals.\nUsing as.list, we’re able to collect each unique value of the categorical variables.\n\nSeason levels contain the four seasons: Spring, Summer, Fall and Winter.\nHoliday levels contain: Holiday and No Holiday.\nFunctioning Day levels contain: Yes and No.\n\n\n\n\n\n# Checked for  each variable's internal structure, denoting the data type of the variables.\nstr(bikes)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                     : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented Bike Count        : num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature(°C)          : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity(%)              : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ Wind speed (m/s)         : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility (10m)         : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ Dew point temperature(°C): num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar Radiation (MJ/m2)  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall(mm)             : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall (cm)            : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning Day          : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n# Created a basic summary of statistics for numeric columns by only selecting numerical variables\nsummary(select(bikes, -Date, -Seasons, -Holiday, -'Functioning Day'))\n\n Rented Bike Count      Hour       Temperature(°C)   Humidity(%)   \n Min.   :   0.0    Min.   : 0.00   Min.   :-17.80   Min.   : 0.00  \n 1st Qu.: 191.0    1st Qu.: 5.75   1st Qu.:  3.50   1st Qu.:42.00  \n Median : 504.5    Median :11.50   Median : 13.70   Median :57.00  \n Mean   : 704.6    Mean   :11.50   Mean   : 12.88   Mean   :58.23  \n 3rd Qu.:1065.2    3rd Qu.:17.25   3rd Qu.: 22.50   3rd Qu.:74.00  \n Max.   :3556.0    Max.   :23.00   Max.   : 39.40   Max.   :98.00  \n Wind speed (m/s) Visibility (10m) Dew point temperature(°C)\n Min.   :0.000    Min.   :  27     Min.   :-30.600          \n 1st Qu.:0.900    1st Qu.: 940     1st Qu.: -4.700          \n Median :1.500    Median :1698     Median :  5.100          \n Mean   :1.725    Mean   :1437     Mean   :  4.074          \n 3rd Qu.:2.300    3rd Qu.:2000     3rd Qu.: 14.800          \n Max.   :7.400    Max.   :2000     Max.   : 27.200          \n Solar Radiation (MJ/m2)  Rainfall(mm)     Snowfall (cm)    \n Min.   :0.0000          Min.   : 0.0000   Min.   :0.00000  \n 1st Qu.:0.0000          1st Qu.: 0.0000   1st Qu.:0.00000  \n Median :0.0100          Median : 0.0000   Median :0.00000  \n Mean   :0.5691          Mean   : 0.1487   Mean   :0.07507  \n 3rd Qu.:0.9300          3rd Qu.: 0.0000   3rd Qu.:0.00000  \n Max.   :3.5200          Max.   :35.0000   Max.   :8.80000  \n\n# Obtained a list of unique levels/values for each categorical variable\nas.list(unique(bikes$Date))\n\n[[1]]\n[1] \"01/12/2017\"\n\n[[2]]\n[1] \"02/12/2017\"\n\n[[3]]\n[1] \"03/12/2017\"\n\n[[4]]\n[1] \"04/12/2017\"\n\n[[5]]\n[1] \"05/12/2017\"\n\n[[6]]\n[1] \"06/12/2017\"\n\n[[7]]\n[1] \"07/12/2017\"\n\n[[8]]\n[1] \"08/12/2017\"\n\n[[9]]\n[1] \"09/12/2017\"\n\n[[10]]\n[1] \"10/12/2017\"\n\n[[11]]\n[1] \"11/12/2017\"\n\n[[12]]\n[1] \"12/12/2017\"\n\n[[13]]\n[1] \"13/12/2017\"\n\n[[14]]\n[1] \"14/12/2017\"\n\n[[15]]\n[1] \"15/12/2017\"\n\n[[16]]\n[1] \"16/12/2017\"\n\n[[17]]\n[1] \"17/12/2017\"\n\n[[18]]\n[1] \"18/12/2017\"\n\n[[19]]\n[1] \"19/12/2017\"\n\n[[20]]\n[1] \"20/12/2017\"\n\n[[21]]\n[1] \"21/12/2017\"\n\n[[22]]\n[1] \"22/12/2017\"\n\n[[23]]\n[1] \"23/12/2017\"\n\n[[24]]\n[1] \"24/12/2017\"\n\n[[25]]\n[1] \"25/12/2017\"\n\n[[26]]\n[1] \"26/12/2017\"\n\n[[27]]\n[1] \"27/12/2017\"\n\n[[28]]\n[1] \"28/12/2017\"\n\n[[29]]\n[1] \"29/12/2017\"\n\n[[30]]\n[1] \"30/12/2017\"\n\n[[31]]\n[1] \"31/12/2017\"\n\n[[32]]\n[1] \"01/01/2018\"\n\n[[33]]\n[1] \"02/01/2018\"\n\n[[34]]\n[1] \"03/01/2018\"\n\n[[35]]\n[1] \"04/01/2018\"\n\n[[36]]\n[1] \"05/01/2018\"\n\n[[37]]\n[1] \"06/01/2018\"\n\n[[38]]\n[1] \"07/01/2018\"\n\n[[39]]\n[1] \"08/01/2018\"\n\n[[40]]\n[1] \"09/01/2018\"\n\n[[41]]\n[1] \"10/01/2018\"\n\n[[42]]\n[1] \"11/01/2018\"\n\n[[43]]\n[1] \"12/01/2018\"\n\n[[44]]\n[1] \"13/01/2018\"\n\n[[45]]\n[1] \"14/01/2018\"\n\n[[46]]\n[1] \"15/01/2018\"\n\n[[47]]\n[1] \"16/01/2018\"\n\n[[48]]\n[1] \"17/01/2018\"\n\n[[49]]\n[1] \"18/01/2018\"\n\n[[50]]\n[1] \"19/01/2018\"\n\n[[51]]\n[1] \"20/01/2018\"\n\n[[52]]\n[1] \"21/01/2018\"\n\n[[53]]\n[1] \"22/01/2018\"\n\n[[54]]\n[1] \"23/01/2018\"\n\n[[55]]\n[1] \"24/01/2018\"\n\n[[56]]\n[1] \"25/01/2018\"\n\n[[57]]\n[1] \"26/01/2018\"\n\n[[58]]\n[1] \"27/01/2018\"\n\n[[59]]\n[1] \"28/01/2018\"\n\n[[60]]\n[1] \"29/01/2018\"\n\n[[61]]\n[1] \"30/01/2018\"\n\n[[62]]\n[1] \"31/01/2018\"\n\n[[63]]\n[1] \"01/02/2018\"\n\n[[64]]\n[1] \"02/02/2018\"\n\n[[65]]\n[1] \"03/02/2018\"\n\n[[66]]\n[1] \"04/02/2018\"\n\n[[67]]\n[1] \"05/02/2018\"\n\n[[68]]\n[1] \"06/02/2018\"\n\n[[69]]\n[1] \"07/02/2018\"\n\n[[70]]\n[1] \"08/02/2018\"\n\n[[71]]\n[1] \"09/02/2018\"\n\n[[72]]\n[1] \"10/02/2018\"\n\n[[73]]\n[1] \"11/02/2018\"\n\n[[74]]\n[1] \"12/02/2018\"\n\n[[75]]\n[1] \"13/02/2018\"\n\n[[76]]\n[1] \"14/02/2018\"\n\n[[77]]\n[1] \"15/02/2018\"\n\n[[78]]\n[1] \"16/02/2018\"\n\n[[79]]\n[1] \"17/02/2018\"\n\n[[80]]\n[1] \"18/02/2018\"\n\n[[81]]\n[1] \"19/02/2018\"\n\n[[82]]\n[1] \"20/02/2018\"\n\n[[83]]\n[1] \"21/02/2018\"\n\n[[84]]\n[1] \"22/02/2018\"\n\n[[85]]\n[1] \"23/02/2018\"\n\n[[86]]\n[1] \"24/02/2018\"\n\n[[87]]\n[1] \"25/02/2018\"\n\n[[88]]\n[1] \"26/02/2018\"\n\n[[89]]\n[1] \"27/02/2018\"\n\n[[90]]\n[1] \"28/02/2018\"\n\n[[91]]\n[1] \"01/03/2018\"\n\n[[92]]\n[1] \"02/03/2018\"\n\n[[93]]\n[1] \"03/03/2018\"\n\n[[94]]\n[1] \"04/03/2018\"\n\n[[95]]\n[1] \"05/03/2018\"\n\n[[96]]\n[1] \"06/03/2018\"\n\n[[97]]\n[1] \"07/03/2018\"\n\n[[98]]\n[1] \"08/03/2018\"\n\n[[99]]\n[1] \"09/03/2018\"\n\n[[100]]\n[1] \"10/03/2018\"\n\n[[101]]\n[1] \"11/03/2018\"\n\n[[102]]\n[1] \"12/03/2018\"\n\n[[103]]\n[1] \"13/03/2018\"\n\n[[104]]\n[1] \"14/03/2018\"\n\n[[105]]\n[1] \"15/03/2018\"\n\n[[106]]\n[1] \"16/03/2018\"\n\n[[107]]\n[1] \"17/03/2018\"\n\n[[108]]\n[1] \"18/03/2018\"\n\n[[109]]\n[1] \"19/03/2018\"\n\n[[110]]\n[1] \"20/03/2018\"\n\n[[111]]\n[1] \"21/03/2018\"\n\n[[112]]\n[1] \"22/03/2018\"\n\n[[113]]\n[1] \"23/03/2018\"\n\n[[114]]\n[1] \"24/03/2018\"\n\n[[115]]\n[1] \"25/03/2018\"\n\n[[116]]\n[1] \"26/03/2018\"\n\n[[117]]\n[1] \"27/03/2018\"\n\n[[118]]\n[1] \"28/03/2018\"\n\n[[119]]\n[1] \"29/03/2018\"\n\n[[120]]\n[1] \"30/03/2018\"\n\n[[121]]\n[1] \"31/03/2018\"\n\n[[122]]\n[1] \"01/04/2018\"\n\n[[123]]\n[1] \"02/04/2018\"\n\n[[124]]\n[1] \"03/04/2018\"\n\n[[125]]\n[1] \"04/04/2018\"\n\n[[126]]\n[1] \"05/04/2018\"\n\n[[127]]\n[1] \"06/04/2018\"\n\n[[128]]\n[1] \"07/04/2018\"\n\n[[129]]\n[1] \"08/04/2018\"\n\n[[130]]\n[1] \"09/04/2018\"\n\n[[131]]\n[1] \"10/04/2018\"\n\n[[132]]\n[1] \"11/04/2018\"\n\n[[133]]\n[1] \"12/04/2018\"\n\n[[134]]\n[1] \"13/04/2018\"\n\n[[135]]\n[1] \"14/04/2018\"\n\n[[136]]\n[1] \"15/04/2018\"\n\n[[137]]\n[1] \"16/04/2018\"\n\n[[138]]\n[1] \"17/04/2018\"\n\n[[139]]\n[1] \"18/04/2018\"\n\n[[140]]\n[1] \"19/04/2018\"\n\n[[141]]\n[1] \"20/04/2018\"\n\n[[142]]\n[1] \"21/04/2018\"\n\n[[143]]\n[1] \"22/04/2018\"\n\n[[144]]\n[1] \"23/04/2018\"\n\n[[145]]\n[1] \"24/04/2018\"\n\n[[146]]\n[1] \"25/04/2018\"\n\n[[147]]\n[1] \"26/04/2018\"\n\n[[148]]\n[1] \"27/04/2018\"\n\n[[149]]\n[1] \"28/04/2018\"\n\n[[150]]\n[1] \"29/04/2018\"\n\n[[151]]\n[1] \"30/04/2018\"\n\n[[152]]\n[1] \"01/05/2018\"\n\n[[153]]\n[1] \"02/05/2018\"\n\n[[154]]\n[1] \"03/05/2018\"\n\n[[155]]\n[1] \"04/05/2018\"\n\n[[156]]\n[1] \"05/05/2018\"\n\n[[157]]\n[1] \"06/05/2018\"\n\n[[158]]\n[1] \"07/05/2018\"\n\n[[159]]\n[1] \"08/05/2018\"\n\n[[160]]\n[1] \"09/05/2018\"\n\n[[161]]\n[1] \"10/05/2018\"\n\n[[162]]\n[1] \"11/05/2018\"\n\n[[163]]\n[1] \"12/05/2018\"\n\n[[164]]\n[1] \"13/05/2018\"\n\n[[165]]\n[1] \"14/05/2018\"\n\n[[166]]\n[1] \"15/05/2018\"\n\n[[167]]\n[1] \"16/05/2018\"\n\n[[168]]\n[1] \"17/05/2018\"\n\n[[169]]\n[1] \"18/05/2018\"\n\n[[170]]\n[1] \"19/05/2018\"\n\n[[171]]\n[1] \"20/05/2018\"\n\n[[172]]\n[1] \"21/05/2018\"\n\n[[173]]\n[1] \"22/05/2018\"\n\n[[174]]\n[1] \"23/05/2018\"\n\n[[175]]\n[1] \"24/05/2018\"\n\n[[176]]\n[1] \"25/05/2018\"\n\n[[177]]\n[1] \"26/05/2018\"\n\n[[178]]\n[1] \"27/05/2018\"\n\n[[179]]\n[1] \"28/05/2018\"\n\n[[180]]\n[1] \"29/05/2018\"\n\n[[181]]\n[1] \"30/05/2018\"\n\n[[182]]\n[1] \"31/05/2018\"\n\n[[183]]\n[1] \"01/06/2018\"\n\n[[184]]\n[1] \"02/06/2018\"\n\n[[185]]\n[1] \"03/06/2018\"\n\n[[186]]\n[1] \"04/06/2018\"\n\n[[187]]\n[1] \"05/06/2018\"\n\n[[188]]\n[1] \"06/06/2018\"\n\n[[189]]\n[1] \"07/06/2018\"\n\n[[190]]\n[1] \"08/06/2018\"\n\n[[191]]\n[1] \"09/06/2018\"\n\n[[192]]\n[1] \"10/06/2018\"\n\n[[193]]\n[1] \"11/06/2018\"\n\n[[194]]\n[1] \"12/06/2018\"\n\n[[195]]\n[1] \"13/06/2018\"\n\n[[196]]\n[1] \"14/06/2018\"\n\n[[197]]\n[1] \"15/06/2018\"\n\n[[198]]\n[1] \"16/06/2018\"\n\n[[199]]\n[1] \"17/06/2018\"\n\n[[200]]\n[1] \"18/06/2018\"\n\n[[201]]\n[1] \"19/06/2018\"\n\n[[202]]\n[1] \"20/06/2018\"\n\n[[203]]\n[1] \"21/06/2018\"\n\n[[204]]\n[1] \"22/06/2018\"\n\n[[205]]\n[1] \"23/06/2018\"\n\n[[206]]\n[1] \"24/06/2018\"\n\n[[207]]\n[1] \"25/06/2018\"\n\n[[208]]\n[1] \"26/06/2018\"\n\n[[209]]\n[1] \"27/06/2018\"\n\n[[210]]\n[1] \"28/06/2018\"\n\n[[211]]\n[1] \"29/06/2018\"\n\n[[212]]\n[1] \"30/06/2018\"\n\n[[213]]\n[1] \"01/07/2018\"\n\n[[214]]\n[1] \"02/07/2018\"\n\n[[215]]\n[1] \"03/07/2018\"\n\n[[216]]\n[1] \"04/07/2018\"\n\n[[217]]\n[1] \"05/07/2018\"\n\n[[218]]\n[1] \"06/07/2018\"\n\n[[219]]\n[1] \"07/07/2018\"\n\n[[220]]\n[1] \"08/07/2018\"\n\n[[221]]\n[1] \"09/07/2018\"\n\n[[222]]\n[1] \"10/07/2018\"\n\n[[223]]\n[1] \"11/07/2018\"\n\n[[224]]\n[1] \"12/07/2018\"\n\n[[225]]\n[1] \"13/07/2018\"\n\n[[226]]\n[1] \"14/07/2018\"\n\n[[227]]\n[1] \"15/07/2018\"\n\n[[228]]\n[1] \"16/07/2018\"\n\n[[229]]\n[1] \"17/07/2018\"\n\n[[230]]\n[1] \"18/07/2018\"\n\n[[231]]\n[1] \"19/07/2018\"\n\n[[232]]\n[1] \"20/07/2018\"\n\n[[233]]\n[1] \"21/07/2018\"\n\n[[234]]\n[1] \"22/07/2018\"\n\n[[235]]\n[1] \"23/07/2018\"\n\n[[236]]\n[1] \"24/07/2018\"\n\n[[237]]\n[1] \"25/07/2018\"\n\n[[238]]\n[1] \"26/07/2018\"\n\n[[239]]\n[1] \"27/07/2018\"\n\n[[240]]\n[1] \"28/07/2018\"\n\n[[241]]\n[1] \"29/07/2018\"\n\n[[242]]\n[1] \"30/07/2018\"\n\n[[243]]\n[1] \"31/07/2018\"\n\n[[244]]\n[1] \"01/08/2018\"\n\n[[245]]\n[1] \"02/08/2018\"\n\n[[246]]\n[1] \"03/08/2018\"\n\n[[247]]\n[1] \"04/08/2018\"\n\n[[248]]\n[1] \"05/08/2018\"\n\n[[249]]\n[1] \"06/08/2018\"\n\n[[250]]\n[1] \"07/08/2018\"\n\n[[251]]\n[1] \"08/08/2018\"\n\n[[252]]\n[1] \"09/08/2018\"\n\n[[253]]\n[1] \"10/08/2018\"\n\n[[254]]\n[1] \"11/08/2018\"\n\n[[255]]\n[1] \"12/08/2018\"\n\n[[256]]\n[1] \"13/08/2018\"\n\n[[257]]\n[1] \"14/08/2018\"\n\n[[258]]\n[1] \"15/08/2018\"\n\n[[259]]\n[1] \"16/08/2018\"\n\n[[260]]\n[1] \"17/08/2018\"\n\n[[261]]\n[1] \"18/08/2018\"\n\n[[262]]\n[1] \"19/08/2018\"\n\n[[263]]\n[1] \"20/08/2018\"\n\n[[264]]\n[1] \"21/08/2018\"\n\n[[265]]\n[1] \"22/08/2018\"\n\n[[266]]\n[1] \"23/08/2018\"\n\n[[267]]\n[1] \"24/08/2018\"\n\n[[268]]\n[1] \"25/08/2018\"\n\n[[269]]\n[1] \"26/08/2018\"\n\n[[270]]\n[1] \"27/08/2018\"\n\n[[271]]\n[1] \"28/08/2018\"\n\n[[272]]\n[1] \"29/08/2018\"\n\n[[273]]\n[1] \"30/08/2018\"\n\n[[274]]\n[1] \"31/08/2018\"\n\n[[275]]\n[1] \"01/09/2018\"\n\n[[276]]\n[1] \"02/09/2018\"\n\n[[277]]\n[1] \"03/09/2018\"\n\n[[278]]\n[1] \"04/09/2018\"\n\n[[279]]\n[1] \"05/09/2018\"\n\n[[280]]\n[1] \"06/09/2018\"\n\n[[281]]\n[1] \"07/09/2018\"\n\n[[282]]\n[1] \"08/09/2018\"\n\n[[283]]\n[1] \"09/09/2018\"\n\n[[284]]\n[1] \"10/09/2018\"\n\n[[285]]\n[1] \"11/09/2018\"\n\n[[286]]\n[1] \"12/09/2018\"\n\n[[287]]\n[1] \"13/09/2018\"\n\n[[288]]\n[1] \"14/09/2018\"\n\n[[289]]\n[1] \"15/09/2018\"\n\n[[290]]\n[1] \"16/09/2018\"\n\n[[291]]\n[1] \"17/09/2018\"\n\n[[292]]\n[1] \"18/09/2018\"\n\n[[293]]\n[1] \"19/09/2018\"\n\n[[294]]\n[1] \"20/09/2018\"\n\n[[295]]\n[1] \"21/09/2018\"\n\n[[296]]\n[1] \"22/09/2018\"\n\n[[297]]\n[1] \"23/09/2018\"\n\n[[298]]\n[1] \"24/09/2018\"\n\n[[299]]\n[1] \"25/09/2018\"\n\n[[300]]\n[1] \"26/09/2018\"\n\n[[301]]\n[1] \"27/09/2018\"\n\n[[302]]\n[1] \"28/09/2018\"\n\n[[303]]\n[1] \"29/09/2018\"\n\n[[304]]\n[1] \"30/09/2018\"\n\n[[305]]\n[1] \"01/10/2018\"\n\n[[306]]\n[1] \"02/10/2018\"\n\n[[307]]\n[1] \"03/10/2018\"\n\n[[308]]\n[1] \"04/10/2018\"\n\n[[309]]\n[1] \"05/10/2018\"\n\n[[310]]\n[1] \"06/10/2018\"\n\n[[311]]\n[1] \"07/10/2018\"\n\n[[312]]\n[1] \"08/10/2018\"\n\n[[313]]\n[1] \"09/10/2018\"\n\n[[314]]\n[1] \"10/10/2018\"\n\n[[315]]\n[1] \"11/10/2018\"\n\n[[316]]\n[1] \"12/10/2018\"\n\n[[317]]\n[1] \"13/10/2018\"\n\n[[318]]\n[1] \"14/10/2018\"\n\n[[319]]\n[1] \"15/10/2018\"\n\n[[320]]\n[1] \"16/10/2018\"\n\n[[321]]\n[1] \"17/10/2018\"\n\n[[322]]\n[1] \"18/10/2018\"\n\n[[323]]\n[1] \"19/10/2018\"\n\n[[324]]\n[1] \"20/10/2018\"\n\n[[325]]\n[1] \"21/10/2018\"\n\n[[326]]\n[1] \"22/10/2018\"\n\n[[327]]\n[1] \"23/10/2018\"\n\n[[328]]\n[1] \"24/10/2018\"\n\n[[329]]\n[1] \"25/10/2018\"\n\n[[330]]\n[1] \"26/10/2018\"\n\n[[331]]\n[1] \"27/10/2018\"\n\n[[332]]\n[1] \"28/10/2018\"\n\n[[333]]\n[1] \"29/10/2018\"\n\n[[334]]\n[1] \"30/10/2018\"\n\n[[335]]\n[1] \"31/10/2018\"\n\n[[336]]\n[1] \"01/11/2018\"\n\n[[337]]\n[1] \"02/11/2018\"\n\n[[338]]\n[1] \"03/11/2018\"\n\n[[339]]\n[1] \"04/11/2018\"\n\n[[340]]\n[1] \"05/11/2018\"\n\n[[341]]\n[1] \"06/11/2018\"\n\n[[342]]\n[1] \"07/11/2018\"\n\n[[343]]\n[1] \"08/11/2018\"\n\n[[344]]\n[1] \"09/11/2018\"\n\n[[345]]\n[1] \"10/11/2018\"\n\n[[346]]\n[1] \"11/11/2018\"\n\n[[347]]\n[1] \"12/11/2018\"\n\n[[348]]\n[1] \"13/11/2018\"\n\n[[349]]\n[1] \"14/11/2018\"\n\n[[350]]\n[1] \"15/11/2018\"\n\n[[351]]\n[1] \"16/11/2018\"\n\n[[352]]\n[1] \"17/11/2018\"\n\n[[353]]\n[1] \"18/11/2018\"\n\n[[354]]\n[1] \"19/11/2018\"\n\n[[355]]\n[1] \"20/11/2018\"\n\n[[356]]\n[1] \"21/11/2018\"\n\n[[357]]\n[1] \"22/11/2018\"\n\n[[358]]\n[1] \"23/11/2018\"\n\n[[359]]\n[1] \"24/11/2018\"\n\n[[360]]\n[1] \"25/11/2018\"\n\n[[361]]\n[1] \"26/11/2018\"\n\n[[362]]\n[1] \"27/11/2018\"\n\n[[363]]\n[1] \"28/11/2018\"\n\n[[364]]\n[1] \"29/11/2018\"\n\n[[365]]\n[1] \"30/11/2018\"\n\nas.list(unique(bikes$Seasons))\n\n[[1]]\n[1] \"Winter\"\n\n[[2]]\n[1] \"Spring\"\n\n[[3]]\n[1] \"Summer\"\n\n[[4]]\n[1] \"Autumn\"\n\nas.list(unique(bikes$Holiday))\n\n[[1]]\n[1] \"No Holiday\"\n\n[[2]]\n[1] \"Holiday\"\n\nas.list(unique(bikes$'Functioning Day'))\n\n[[1]]\n[1] \"Yes\"\n\n[[2]]\n[1] \"No\"\n\n\n\n\nNext we’ll convert the Date column into month/day/year to more easily read and viewed the data set.\n\n\n\n# Using lubridate, we're reformmating the date to be m/d/y. First we use as.Date to parse the dates and allow them to be readable in R then we reformat them as m/d/y.\nbikes &lt;- bikes %&gt;%\n  mutate(Date = dmy(Date))\n\n\n\nNow we’re going to change the categorical variables to have a class of factor. This’ll allow us to use the factors/levels of these variables in statistical modeling for us to better understand how these different levels are affected.\n\n\n\n# Used mutate to change the categorical variable class characters to factors.\n\nbikes &lt;- bikes %&gt;%\n  mutate(Seasons = as.factor(Seasons),\n         Holiday = as.factor(Holiday),\n         `Functioning Day` = as.factor(`Functioning Day`))\n\n\n\nLast, we’re going rename all of the variables to have easy names to reference. Using the clean_names function, this’ll make it easier for us to reference in our later queries due to the universal naming convention.\n\n\n\n# Used clean_names function from the janitor package to lowercase and insert '_' names for all columns. \nbikes &lt;- bikes %&gt;%\n  clean_names()\n\n\n\nNow that our data is clean up, we’re going to create summary statistics about bike rental count across our categorical variables. When creating the first summary statistics for bike rentals, bike functioning day that equaled no contained no information to find a statistic on because no bikes were rented on those days. As a result, we created another summary filtering to only keep where bike functioning day equaled to yes.\n\n\n\n# Created a bike rental summary grouped by seasons, holiday, and functioning_day\nbike_rental_summary &lt;- bikes %&gt;%\n  group_by(seasons, holiday, functioning_day) %&gt;%\n  summarise(bike_rental_min = min(rented_bike_count),\n               bike_rental_median = median(rented_bike_count),\n               bike_rental_max = max(rented_bike_count),\n               bike_rental_mean = mean(rented_bike_count),\n               bike_rental_sd = sd(rented_bike_count))\nbike_rental_summary\n\n# A tibble: 11 × 8\n# Groups:   seasons, holiday [8]\n   seasons holiday    functioning_day bike_rental_min bike_rental_median\n   &lt;fct&gt;   &lt;fct&gt;      &lt;fct&gt;                     &lt;dbl&gt;              &lt;dbl&gt;\n 1 Autumn  Holiday    No                            0                 0 \n 2 Autumn  Holiday    Yes                         105               900 \n 3 Autumn  No Holiday No                            0                 0 \n 4 Autumn  No Holiday Yes                           2               852 \n 5 Spring  Holiday    Yes                          11               366.\n 6 Spring  No Holiday No                            0                 0 \n 7 Spring  No Holiday Yes                           2               605 \n 8 Summer  Holiday    Yes                         218               925 \n 9 Summer  No Holiday Yes                           9               904.\n10 Winter  Holiday    Yes                           3               138 \n11 Winter  No Holiday Yes                           7               212 \n# ℹ 3 more variables: bike_rental_max &lt;dbl&gt;, bike_rental_mean &lt;dbl&gt;,\n#   bike_rental_sd &lt;dbl&gt;\n\n# Further subsetted where functioning day is yes\nbike_rental_summary_functional &lt;- bikes %&gt;%\n  filter(functioning_day == \"Yes\") %&gt;%\n  group_by(seasons, holiday, functioning_day) %&gt;%\n  summarise(bike_rental_min = min(rented_bike_count),\n               bike_rental_median = median(rented_bike_count),\n               bike_rental_max = max(rented_bike_count),\n               bike_rental_mean = mean(rented_bike_count),\n               bike_rental_sd = sd(rented_bike_count))\nbike_rental_summary_functional\n\n# A tibble: 8 × 8\n# Groups:   seasons, holiday [8]\n  seasons holiday    functioning_day bike_rental_min bike_rental_median\n  &lt;fct&gt;   &lt;fct&gt;      &lt;fct&gt;                     &lt;dbl&gt;              &lt;dbl&gt;\n1 Autumn  Holiday    Yes                         105               900 \n2 Autumn  No Holiday Yes                           2               852 \n3 Spring  Holiday    Yes                          11               366.\n4 Spring  No Holiday Yes                           2               605 \n5 Summer  Holiday    Yes                         218               925 \n6 Summer  No Holiday Yes                           9               904.\n7 Winter  Holiday    Yes                           3               138 \n8 Winter  No Holiday Yes                           7               212 \n# ℹ 3 more variables: bike_rental_max &lt;dbl&gt;, bike_rental_mean &lt;dbl&gt;,\n#   bike_rental_sd &lt;dbl&gt;\n\n\n\n\nIn order to simplify our previous analysis and initial bikes data set, we’re going to summarize across the hours so each day has one observation associated with it along with each weather condition. We’ll do this by summing up the total amount of bikes rented per hour per day to return This daily rental summary gives us a much better grasp of daily statistics compared to the initial bike data which filtered the data per each hour of the day for bike rentals, whereas this new summary combines all of those hour values into one day to give us a total amount of bikes rented per day. We continue to filter by a functioning day of yes so it doesn’t skew our summary of statistics regarding bike rental data and the rest of the numerical variables. Additionally, when filtering out functioning day ‘No’, the total data goes from 365 days to 353 days indicating that there were 12 days that no bikes were rented out to people.\n\n\n\ndaily_rental_summary &lt;- bikes %&gt;%\n  filter(functioning_day == \"Yes\") %&gt;%\n  group_by(date, seasons, holiday) %&gt;%\n  summarise(bike_count_sum = sum(rented_bike_count),\n               rainfall_mm_sum = sum(rainfall_mm),\n               snowfall_cm_sum = sum(snowfall_cm),\n               temperature_c_mean = mean(temperature_c),\n               humidity_percent_mean = mean(humidity_percent),\n               wind_speed_mean = mean(wind_speed_m_s),\n               visibility_mean = mean(visibility_10m),\n               dew_point_temp_c_mean = mean(dew_point_temperature_c),\n               solar_radiation_mean = mean(solar_radiation_mj_m2),\n               rainfall_mm_mean = mean(rainfall_mm),\n               snowfall_cm_mean = mean(snowfall_cm))\ndaily_rental_summary\n\n# A tibble: 353 × 14\n# Groups:   date, seasons [353]\n   date       seasons holiday    bike_count_sum rainfall_mm_sum snowfall_cm_sum\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;               &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;\n 1 2017-12-01 Winter  No Holiday           9539             0               0  \n 2 2017-12-02 Winter  No Holiday           8523             0               0  \n 3 2017-12-03 Winter  No Holiday           7222             4               0  \n 4 2017-12-04 Winter  No Holiday           8729             0.1             0  \n 5 2017-12-05 Winter  No Holiday           8307             0               0  \n 6 2017-12-06 Winter  No Holiday           6669             1.3             8.6\n 7 2017-12-07 Winter  No Holiday           8549             0              10.4\n 8 2017-12-08 Winter  No Holiday           8032             0               0  \n 9 2017-12-09 Winter  No Holiday           7233             0               0  \n10 2017-12-10 Winter  No Holiday           3453             4.1            32.5\n# ℹ 343 more rows\n# ℹ 8 more variables: temperature_c_mean &lt;dbl&gt;, humidity_percent_mean &lt;dbl&gt;,\n#   wind_speed_mean &lt;dbl&gt;, visibility_mean &lt;dbl&gt;, dew_point_temp_c_mean &lt;dbl&gt;,\n#   solar_radiation_mean &lt;dbl&gt;, rainfall_mm_mean &lt;dbl&gt;, snowfall_cm_mean &lt;dbl&gt;\n\n\n\n\nNow with this new analysis, we’re going to create a summary statistic of our daily rental summary to explore some data. As seen below, there are a total of 353 observations, denoted by ‘date’ in this data set. Of those dates 81 of them are from the Autumn, 90 from the Winter, 90 from the Spring, and 92 from the Summer. Out of the 353 days, 17 of those days are defined as holidays and 336 are not considered holidays. There’s a handful of data to go through for the weather conditions, but we’ll create a correlation matrix and some plots below to explore those.\n\n\n\n# Created a summary statistics for the daily_rental_summary\nsummary(daily_rental_summary)\n\n      date              seasons         holiday    bike_count_sum \n Min.   :2017-12-01   Autumn:81   Holiday   : 17   Min.   :  977  \n 1st Qu.:2018-02-27   Spring:90   No Holiday:336   1st Qu.: 6967  \n Median :2018-05-28   Summer:92                    Median :18563  \n Mean   :2018-05-28   Winter:90                    Mean   :17485  \n 3rd Qu.:2018-08-24                                3rd Qu.:26285  \n Max.   :2018-11-30                                Max.   :36149  \n rainfall_mm_sum  snowfall_cm_sum  temperature_c_mean humidity_percent_mean\n Min.   : 0.000   Min.   : 0.000   Min.   :-14.738    Min.   :22.25        \n 1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.:  3.304    1st Qu.:47.58        \n Median : 0.000   Median : 0.000   Median : 13.738    Median :57.17        \n Mean   : 3.576   Mean   : 1.863   Mean   : 12.776    Mean   :58.17        \n 3rd Qu.: 0.500   3rd Qu.: 0.000   3rd Qu.: 22.592    3rd Qu.:67.71        \n Max.   :95.500   Max.   :78.700   Max.   : 33.742    Max.   :95.88        \n wind_speed_mean  visibility_mean  dew_point_temp_c_mean solar_radiation_mean\n Min.   :0.6625   Min.   : 214.3   Min.   :-27.750       Min.   :0.02917     \n 1st Qu.:1.3042   1st Qu.:1087.0   1st Qu.: -5.188       1st Qu.:0.28333     \n Median :1.6583   Median :1557.8   Median :  4.612       Median :0.56500     \n Mean   :1.7261   Mean   :1434.0   Mean   :  3.954       Mean   :0.56773     \n 3rd Qu.:1.9542   3rd Qu.:1874.3   3rd Qu.: 14.921       3rd Qu.:0.82000     \n Max.   :4.0000   Max.   :2000.0   Max.   : 25.038       Max.   :1.21667     \n rainfall_mm_mean  snowfall_cm_mean \n Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.00000   Median :0.00000  \n Mean   :0.15072   Mean   :0.07762  \n 3rd Qu.:0.02083   3rd Qu.:0.00000  \n Max.   :3.97917   Max.   :3.27917  \n\n\n\nBelow I have created the first plot, a scatter plot to look at the relationship between bike count rentals and temperature across seasons. The plot shows a strong positive correlation between these two variables, as one variable increases, the other increases. As temperature increases, bike rentals also increases. There are a cluster of data points where the temperature is below 10 degrees celcius with under 10,000 bike rentals per day; those data points most likely represent days colder days with potential less favorable biking conditions, as seen, denoted by the winter data points. Then there is a cluster of data points from 20 to 25 degrees celcius with more than 30,000 bike rentals a day; that cluster represents and shows that perhaps bike riders enjoy more warm weather, denoted by a mix of the Spring, Autumn, and Summer data points. Additionally, the data points are much more spread from 10 to 30 degrees celcius, perhaps indicating that people enjoy riding in more warm weather. However, there are also days where the temperatures are higher but bike rentals are low… this could be due to other weather conditions like some rainfall, wind speeds, holidays, etc.\n\n\n# Created a scatterplot to explore\nscatter_plot &lt;- ggplot(daily_rental_summary,\n                    aes(x = temperature_c_mean, y = bike_count_sum, color = seasons)) +\n                  geom_jitter(width = 0.2, alpha = 0.6) +\n                  ggtitle(label = \"The Relationship between Bike Count Rental \\n and Temperature (C) across Seasons\",\n                          subtitle = \"Scatter Plot\") +\n                  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n                        plot.subtitle = element_text(hjust = 0.5)) +\n                  labs(x = \"Temperature \\n (in Celcius)\", \n                       y = \"Bike Rentals \\n (bikes rented per day)\") +\n                  scale_fill_discrete(\"Temperature\")\nscatter_plot\n\n\n\n\n\n\n\n\n\nFor biking novices like myself, weather conditions that affect biking such as rainfall, snowfall, etc. are apparent, which is I’m interested in how visibility may affect bike rentals. Below I have created a plot between visibility and bike rentals across seasons and faceted by holidays. Upon observation there is a slight positive correlation on non-holidays with more rentals based on more visibility. For the holiday facet, there is not much of a pattern with rentals being spread across the entire range of visibility perhaps showcasing that visibility doesn’t affect bike rental rate as much on holidays. When looking at both holiday and non-holiday data, Summer and Autumn months produce a higher number of bike rentals compared to Winter and Spring months. Summer months show the highest number of rentals on non-holidays from 500m to 2,000m indicating that summer weather encourages biking regardless of the visibility. In conclusion, the higher the visibility, the more bike rentals there are as the plots showcase a strong positive relationship between the two variables.\n\n\nfacet_plot &lt;- ggplot(daily_rental_summary,\n                    aes(x = visibility_mean, y = bike_count_sum, color = seasons)) + \n                  geom_jitter(width = 0.2, alpha = 0.6) +\n                  facet_wrap(~ holiday) +\n                  ggtitle(label = \"The Relationship between Bike Count Rental \\n and Visibility (by 10m) across Seasons with Holiday facet\",\n                          subtitle = \"Scatter Plot\") +\n                  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n                        plot.subtitle = element_text(hjust = 0.5)) +\n                  labs(x = \"Visibility \\n (by 10m)\", \n                       y = \"Bike Rentals \\n (bikes rented per day)\")\nfacet_plot\n\n\n\n\n\n\n\n\n\nNext is the reported correlation matrix for all of the numeric variables; since there are so many, I will pick and choose a handful of correlations (relationship between variables) related to bike_count_sum to explore. Looking at bike_count_sum and its correlations in the first column, we can see that there are some strong positive correlations (as one variable increases, the other also increases), mainly bike_count_sum and temperature with a correlation of 0.753 and bike_count_sum and solar_radiation with a correlation of 0.736. From the first observation, we can see that higher temperatures are associated with a higher number of bike rentals; bike riders enjoy good weather and warmer temperatures when riding bikes. This supported our first scatterplot as we a strong positive correlation from the plot. The second correlation shows that higher solar radiation, i.e. more sun, also correlates with more bike rentals. Additionally, there are many weak negative correlations (as one variable increases, the other one one decreases) with bike_count such as: wind_speed_mean (-0.193), rainfall_mm_mean (-0.237), and snowfall_mm_mean (-0.265). Bike rental counts are expected to be negatively associated with these weather variables because high wind speeds, rainfall, and snowfall affect biking conditions and enviroments, and as a result tend to reduce bike rental rates.\n\n\n# Created a filtered data frame to only show numeric variables to create correlation matrix\nnumeric_daily_rental_summary &lt;- daily_rental_summary %&gt;%\n  ungroup() %&gt;%\n  select(where(is.numeric)) \nnumeric_daily_rental_summary\n\n# A tibble: 353 × 11\n   bike_count_sum rainfall_mm_sum snowfall_cm_sum temperature_c_mean\n            &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;              &lt;dbl&gt;\n 1           9539             0               0              -2.45  \n 2           8523             0               0               1.32  \n 3           7222             4               0               4.88  \n 4           8729             0.1             0              -0.304 \n 5           8307             0               0              -4.46  \n 6           6669             1.3             8.6             0.0458\n 7           8549             0              10.4             1.09  \n 8           8032             0               0              -3.82  \n 9           7233             0               0              -0.846 \n10           3453             4.1            32.5             1.19  \n# ℹ 343 more rows\n# ℹ 7 more variables: humidity_percent_mean &lt;dbl&gt;, wind_speed_mean &lt;dbl&gt;,\n#   visibility_mean &lt;dbl&gt;, dew_point_temp_c_mean &lt;dbl&gt;,\n#   solar_radiation_mean &lt;dbl&gt;, rainfall_mm_mean &lt;dbl&gt;, snowfall_cm_mean &lt;dbl&gt;\n\n# Referenced previously created filtered data frame to create a correlation matrix between all of the numeric variables\nnum_cor_matrix &lt;- numeric_daily_rental_summary %&gt;%\n  cor()\nnum_cor_matrix\n\n                      bike_count_sum rainfall_mm_sum snowfall_cm_sum\nbike_count_sum            1.00000000     -0.23910905     -0.26529110\nrainfall_mm_sum          -0.23910905      1.00000000     -0.02313404\nsnowfall_cm_sum          -0.26529110     -0.02313404      1.00000000\ntemperature_c_mean        0.75307673      0.14451727     -0.26696366\nhumidity_percent_mean     0.03588697      0.52864263      0.06539191\nwind_speed_mean          -0.19288142     -0.10167578      0.02088156\nvisibility_mean           0.16599375     -0.22199387     -0.10188902\ndew_point_temp_c_mean     0.65047655      0.26456621     -0.20955286\nsolar_radiation_mean      0.73589290     -0.32270413     -0.23343056\nrainfall_mm_mean         -0.23686365      0.99791474     -0.02360438\nsnowfall_cm_mean         -0.26529110     -0.02313404      1.00000000\n                      temperature_c_mean humidity_percent_mean wind_speed_mean\nbike_count_sum               0.753076732            0.03588697     -0.19288142\nrainfall_mm_sum              0.144517274            0.52864263     -0.10167578\nsnowfall_cm_sum             -0.266963662            0.06539191      0.02088156\ntemperature_c_mean           1.000000000            0.40416749     -0.26072179\nhumidity_percent_mean        0.404167486            1.00000000     -0.23425778\nwind_speed_mean             -0.260721792           -0.23425778      1.00000000\nvisibility_mean              0.002336683           -0.55917733      0.20602264\ndew_point_temp_c_mean        0.962796255            0.63204729     -0.28770322\nsolar_radiation_mean         0.550274301           -0.27444967      0.09612635\nrainfall_mm_mean             0.144573425            0.52795952     -0.09863450\nsnowfall_cm_mean            -0.266963662            0.06539191      0.02088156\n                      visibility_mean dew_point_temp_c_mean\nbike_count_sum            0.165993749             0.6504765\nrainfall_mm_sum          -0.221993866             0.2645662\nsnowfall_cm_sum          -0.101889019            -0.2095529\ntemperature_c_mean        0.002336683             0.9627963\nhumidity_percent_mean    -0.559177334             0.6320473\nwind_speed_mean           0.206022636            -0.2877032\nvisibility_mean           1.000000000            -0.1535516\ndew_point_temp_c_mean    -0.153551591             1.0000000\nsolar_radiation_mean      0.271395906             0.3831571\nrainfall_mm_mean         -0.218236382             0.2644913\nsnowfall_cm_mean         -0.101889019            -0.2095529\n                      solar_radiation_mean rainfall_mm_mean snowfall_cm_mean\nbike_count_sum                  0.73589290      -0.23686365      -0.26529110\nrainfall_mm_sum                -0.32270413       0.99791474      -0.02313404\nsnowfall_cm_sum                -0.23343056      -0.02360438       1.00000000\ntemperature_c_mean              0.55027430       0.14457343      -0.26696366\nhumidity_percent_mean          -0.27444967       0.52795952       0.06539191\nwind_speed_mean                 0.09612635      -0.09863450       0.02088156\nvisibility_mean                 0.27139591      -0.21823638      -0.10188902\ndew_point_temp_c_mean           0.38315713       0.26449127      -0.20955286\nsolar_radiation_mean            1.00000000      -0.32079734      -0.23343056\nrainfall_mm_mean               -0.32079734       1.00000000      -0.02360438\nsnowfall_cm_mean               -0.23343056      -0.02360438       1.00000000\n\n\n\n\n\n\nFor this next section, we’ll be splitting the data: 75% of the data into the training set and 25% of it into the test set. We’ll also stratify the data by seasons. Additionally, on the training set we’ll create a 10 fold CV split, which randomly splits the data into V groups of roughly equal size (“folds”).\n\n\n# Split the data\nset.seed(123)\nbike_split &lt;- initial_split(daily_rental_summary, prop = 3/4, strata = seasons)\ntrain_data &lt;- training(bike_split)\ntest_data &lt;- testing(bike_split)\n\n\n# Created a 10 fold CV split\ncv_folds_10 &lt;- vfold_cv(data = train_data, v = 10)\n\n\n\n\n\nNow we’re going to work on creating the recipes!\n\n\nFirst recipe!\n\n\nHere we’re going to fix up the date variable a bit, standardize the numeric variables, and create dummy variables for the seasons, holiday, and our new day type!\n\n\n# Creating the first recipe\nrecipe_1 &lt;- recipe(bike_count_sum ~ ., data = train_data) %&gt;%\n  step_date(date, features = \"dow\") %&gt;% # Used to extract day of week\n  step_rm(date) %&gt;%\n  step_mutate(day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) %&gt;% # Creating day_type to categorical variable with 2 levels: weekend and weekday\n  step_rm(date_dow) %&gt;% # Used as a general variable filter \n  # step_rm(dow_day) %&gt;% # Removed the intermediate variable created\n  step_normalize(all_numeric()) %&gt;% # Standardizes all numeric variables\n  step_dummy(seasons, holiday, day_type) # Created dummy variables\n\n\n# Checking recipe\nprep_recipe1 &lt;- recipe_1 %&gt;% \n  prep(training = train_data)\n\nbaked_data1 &lt;- bake(prep_recipe1, new_data = NULL)\n\nhead(baked_data1)\n\n# A tibble: 6 × 16\n  rainfall_mm_sum snowfall_cm_sum temperature_c_mean humidity_percent_mean\n            &lt;dbl&gt;           &lt;dbl&gt;              &lt;dbl&gt;                 &lt;dbl&gt;\n1          -0.297          -0.218              0.943                 0.214\n2          -0.297          -0.218              0.978                 0.818\n3          -0.177          -0.218              0.800                -0.116\n4          -0.297          -0.218              0.760                -0.666\n5          -0.297          -0.218              0.783                -0.613\n6          -0.297          -0.218              0.867                -0.571\n# ℹ 12 more variables: wind_speed_mean &lt;dbl&gt;, visibility_mean &lt;dbl&gt;,\n#   dew_point_temp_c_mean &lt;dbl&gt;, solar_radiation_mean &lt;dbl&gt;,\n#   rainfall_mm_mean &lt;dbl&gt;, snowfall_cm_mean &lt;dbl&gt;, bike_count_sum &lt;dbl&gt;,\n#   seasons_Spring &lt;dbl&gt;, seasons_Summer &lt;dbl&gt;, seasons_Winter &lt;dbl&gt;,\n#   holiday_No.Holiday &lt;dbl&gt;, day_type_weekend &lt;dbl&gt;\n\n\n\nSecond recipe!\n\n\nNow we’re going to follow the same steps as the first recipe and add interactions between seasons and holiday, seasons and temp, temp and rainfall.\n\n\n# Creating the second recipe\nrecipe_2 &lt;- recipe(\"bike_count_sum\" ~ ., data = train_data) %&gt;%\n  step_date(date, features = \"dow\") %&gt;% # Used to extract day of week\n  step_rm(date) %&gt;%\n  step_mutate(day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) %&gt;% # Creating day_type to categorical variable with 2 levels: weekend and weekday\n  step_rm(date_dow) %&gt;% # Used as a general variable filter \n  # step_rm(dow_day) %&gt;% # Removed the intermediate variable created\n  step_normalize(all_numeric()) %&gt;% # Standardizes all numeric variables\n  step_dummy(seasons, holiday, day_type) %&gt;% # Created dummy variables # Created dummy variables\n  step_interact(~ starts_with(\"seasons\"):holiday_No.Holiday) %&gt;% \n                  step_interact(~ starts_with(\"seasons\"):temperature_c_mean) %&gt;% \n                  step_interact(~ temperature_c_mean:rainfall_mm_sum) # Created for the interactions\n\n\n# Checking recipe 2\nprep_recipe2 &lt;- recipe_2 %&gt;% \n  prep(training = train_data)\n\nbaked_data2 &lt;- bake(prep_recipe2, new_data = NULL)\n\nhead(baked_data2)\n\n# A tibble: 6 × 26\n  bike_count_sum rainfall_mm_sum snowfall_cm_sum temperature_c_mean\n           &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;              &lt;dbl&gt;\n1           1.40          -0.297          -0.218              0.943\n2           1.07          -0.297          -0.218              0.978\n3           1.33          -0.177          -0.218              0.800\n4           1.27          -0.297          -0.218              0.760\n5           1.12          -0.297          -0.218              0.783\n6           1.37          -0.297          -0.218              0.867\n# ℹ 22 more variables: humidity_percent_mean &lt;dbl&gt;, wind_speed_mean &lt;dbl&gt;,\n#   visibility_mean &lt;dbl&gt;, dew_point_temp_c_mean &lt;dbl&gt;,\n#   solar_radiation_mean &lt;dbl&gt;, rainfall_mm_mean &lt;dbl&gt;, snowfall_cm_mean &lt;dbl&gt;,\n#   seasons_Spring &lt;dbl&gt;, seasons_Summer &lt;dbl&gt;, seasons_Winter &lt;dbl&gt;,\n#   holiday_No.Holiday &lt;dbl&gt;, day_type_weekend &lt;dbl&gt;,\n#   seasons_Spring_x_holiday_No.Holiday &lt;dbl&gt;,\n#   seasons_Summer_x_holiday_No.Holiday &lt;dbl&gt;, …\n\n\n\nThird recipe!\n\n\nNow we’re going to follow the same steps as the second recipe and add quadratic terms for each numeric predictor\n\n\n# Creating the third recipe\nrecipe_3 &lt;- recipe(bike_count_sum ~ ., data = train_data) %&gt;%\n  step_date(date, features = \"dow\") %&gt;% # Used to extract day of week\n  step_rm(date) %&gt;%\n  step_mutate(day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) %&gt;% # Creating day_type to categorical variable with 2 levels: weekend and weekday\n  step_rm(date_dow) %&gt;% # Used as a general variable filter \n  # step_rm(dow_day) %&gt;% # Removed the intermediate variable created\n  step_normalize(all_numeric()) %&gt;% # Standardizes all numeric variables\n  step_dummy(seasons, holiday, day_type) %&gt;% # Created dummy variables # Created dummy variables\n  step_interact(~ starts_with(\"seasons\"):holiday_No.Holiday) %&gt;% \n                  step_interact(~ starts_with(\"seasons\"):temperature_c_mean) %&gt;% \n                  step_interact(~ temperature_c_mean:rainfall_mm_sum) %&gt;% # Created for the interactions\n  step_poly(rainfall_mm_sum, snowfall_cm_sum, temperature_c_mean, humidity_percent_mean, wind_speed_mean, visibility_mean, dew_point_temp_c_mean, solar_radiation_mean, rainfall_mm_mean, snowfall_cm_mean, degree = 2)\n\n\n# Checking recipe 3\nprep_recipe3 &lt;- recipe_3 %&gt;% \n  prep(training = train_data)\n\nbaked_data3 &lt;- bake(prep_recipe3, new_data = NULL)\n\nhead(baked_data3)\n\n# A tibble: 6 × 36\n  bike_count_sum seasons_Spring seasons_Summer seasons_Winter holiday_No.Holiday\n           &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;              &lt;dbl&gt;\n1           1.40              0              0              0                  1\n2           1.07              0              0              0                  1\n3           1.33              0              0              0                  1\n4           1.27              0              0              0                  1\n5           1.12              0              0              0                  1\n6           1.37              0              0              0                  1\n# ℹ 31 more variables: day_type_weekend &lt;dbl&gt;,\n#   seasons_Spring_x_holiday_No.Holiday &lt;dbl&gt;,\n#   seasons_Summer_x_holiday_No.Holiday &lt;dbl&gt;,\n#   seasons_Winter_x_holiday_No.Holiday &lt;dbl&gt;,\n#   seasons_Spring_x_temperature_c_mean &lt;dbl&gt;,\n#   seasons_Summer_x_temperature_c_mean &lt;dbl&gt;,\n#   seasons_Winter_x_temperature_c_mean &lt;dbl&gt;, …\n\n\n\n\n\n\nNow we set up our linear model to use the lm engine and fit the models accordingly.\n\n\n# Specifying linear model\nbike_lm &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\n# Creating work flows for each recipe\nrecipe_wf1 &lt;- workflow() %&gt;%\n  add_recipe(recipe_1) %&gt;%\n  add_model(bike_lm)\n\nrecipe_wf2 &lt;- workflow() %&gt;%\n  add_recipe(recipe_2) %&gt;%\n  add_model(bike_lm)\n\nrecipe_wf3 &lt;- workflow() %&gt;%\n  add_recipe(recipe_3) %&gt;%\n  add_model(bike_lm)\n\n# Fitting the models using 10 fold CV via fit_resamples()\nrecipe_fit1 &lt;- recipe_wf1 %&gt;%\n  fit_resamples(cv_folds_10)\n\nrecipe_fit2 &lt;- recipe_wf2 %&gt;%\n  fit_resamples(cv_folds_10)\n\nrecipe_fit3 &lt;- recipe_wf3 %&gt;%\n  fit_resamples(cv_folds_10)\n\n# Binding samples together for best model\nrbind(recipe_fit1 %&gt;% collect_metrics(),\n      recipe_fit2 %&gt;% collect_metrics(),\n      recipe_fit3 %&gt;% collect_metrics())\n\nError in `estimate_tune_results()`:\n! All models failed. Run `show_notes(.Last.tune.result)` for more information.\n\n\n\nAs the final steps we’ll use our best model to fit the model on the entire training data set, compute the RMSE, and obtain the final model.\n\n\n# Assigning the best model\nbest_model &lt;- \n  \n# Using last_fit on full training data\nentire_training &lt;- last_fit(best_model, split = bike_split)\n\nError: object 'best_model' not found\n\n# Check RMSE\nfinal_data &lt;- collect_metrics(entire_training)\n\nError: object 'entire_training' not found\n\nfinal_data\n\nError: object 'final_data' not found\n\nfinal_model_coefficients &lt;- entire_training %&gt;%\n  extract_fit_parsnip() %&gt;%\n  tidy()\n\nError: object 'entire_training' not found\n\nfinal_model_coefficients\n\nError: object 'final_model_coefficients' not found"
  },
  {
    "objectID": "Homework8Tuong.html#basic-modeling-practice",
    "href": "Homework8Tuong.html#basic-modeling-practice",
    "title": "Week 8 - Basic Modeling Practice",
    "section": "",
    "text": "The purpose of this assignment is to create an EDA, exploratory data analysis, document for a data set about Seoul Bikes. We do this in order to better understand our data. The document will go through the following:\n\n\nChecking the data.\nSplitting the data.\nFitting MLR models.\n\n\nNote: Items are numbered for ease of grading; regardless, the document is still to be read in narrative form.\n\n\n\n\nStaring off, we’re going to install and load the necessary packages to create the EDA. Then we’ll read in the data.\n\n\n# Installed packages\n# install.packages(\"tidyverse\")\n# install.packages(\"tidymodels\") # For use of tidymodel functions\n# install.packages(\"lubridate\")\n# install.packages(\"janitor\")\n\n\n# Loading in libraries\nlibrary(tidyverse)\nlibrary(tidymodels)  \nlibrary(lubridate)\nlibrary(janitor)\nlibrary(readr)  \n\n\n# Read in data\nbikes &lt;- readr::read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\", locale = locale(encoding = \"latin1\"))\nbikes\n\n# A tibble: 8,760 × 14\n   Date       `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n   &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 01/12/2017                 254     0              -5.2            37\n 2 01/12/2017                 204     1              -5.5            38\n 3 01/12/2017                 173     2              -6              39\n 4 01/12/2017                 107     3              -6.2            40\n 5 01/12/2017                  78     4              -6              36\n 6 01/12/2017                 100     5              -6.4            37\n 7 01/12/2017                 181     6              -6.6            35\n 8 01/12/2017                 460     7              -7.4            38\n 9 01/12/2017                 930     8              -7.6            37\n10 01/12/2017                 490     9              -6.5            27\n# ℹ 8,750 more rows\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(°C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;chr&gt;, Holiday &lt;chr&gt;,\n#   `Functioning Day` &lt;chr&gt;\n\n\n\n\nNext we’re going to check for missingness within our data set. As seen below, there are no columns missing any values or data, so we can move forward with continuing to check the data.\n\n\n\n# Checked for missingness - to see if there are any missing values in the data set.\nmissingnesscheck &lt;- is.na(bikes) %&gt;% colSums()\nmissingnesscheck\n\n                     Date         Rented Bike Count                      Hour \n                        0                         0                         0 \n          Temperature(°C)               Humidity(%)          Wind speed (m/s) \n                        0                         0                         0 \n         Visibility (10m) Dew point temperature(°C)   Solar Radiation (MJ/m2) \n                        0                         0                         0 \n             Rainfall(mm)             Snowfall (cm)                   Seasons \n                        0                         0                         0 \n                  Holiday           Functioning Day \n                        0                         0 \n\n\n\n\nNow we’ll check the column types and their values to ensure it makes sense. We’ll do a basic summary of statistics for numeric columns and then check for the unique values of the categorical variables.\n\nUsing the str function, when checking for the column types and values, it does indicate that the variables contain the correct column types and values accordingly. There are a total of 14 variables: 10 are numeric types (Rented Bike Count, Hour, Temperature, Humidity, Wind speed, Visibility, Dew point temperature, Solar Radiation, Rainfall, Snowfall) and 4 are character types (Date, Seasons, Holidays, Functioning Day).\nUsing the summary function we selected numeric columns to create summary statistics for, which include the minimum, 1st quartile, median, mean, 3rd quartile, and maximum. These summary statistics give us some insight regarding weather conditions and total bike rentals.\nUsing as.list, we’re able to collect each unique value of the categorical variables.\n\nSeason levels contain the four seasons: Spring, Summer, Fall and Winter.\nHoliday levels contain: Holiday and No Holiday.\nFunctioning Day levels contain: Yes and No.\n\n\n\n\n\n# Checked for  each variable's internal structure, denoting the data type of the variables.\nstr(bikes)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                     : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented Bike Count        : num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature(°C)          : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity(%)              : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ Wind speed (m/s)         : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility (10m)         : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ Dew point temperature(°C): num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar Radiation (MJ/m2)  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall(mm)             : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall (cm)            : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning Day          : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n# Created a basic summary of statistics for numeric columns by only selecting numerical variables\nsummary(select(bikes, -Date, -Seasons, -Holiday, -'Functioning Day'))\n\n Rented Bike Count      Hour       Temperature(°C)   Humidity(%)   \n Min.   :   0.0    Min.   : 0.00   Min.   :-17.80   Min.   : 0.00  \n 1st Qu.: 191.0    1st Qu.: 5.75   1st Qu.:  3.50   1st Qu.:42.00  \n Median : 504.5    Median :11.50   Median : 13.70   Median :57.00  \n Mean   : 704.6    Mean   :11.50   Mean   : 12.88   Mean   :58.23  \n 3rd Qu.:1065.2    3rd Qu.:17.25   3rd Qu.: 22.50   3rd Qu.:74.00  \n Max.   :3556.0    Max.   :23.00   Max.   : 39.40   Max.   :98.00  \n Wind speed (m/s) Visibility (10m) Dew point temperature(°C)\n Min.   :0.000    Min.   :  27     Min.   :-30.600          \n 1st Qu.:0.900    1st Qu.: 940     1st Qu.: -4.700          \n Median :1.500    Median :1698     Median :  5.100          \n Mean   :1.725    Mean   :1437     Mean   :  4.074          \n 3rd Qu.:2.300    3rd Qu.:2000     3rd Qu.: 14.800          \n Max.   :7.400    Max.   :2000     Max.   : 27.200          \n Solar Radiation (MJ/m2)  Rainfall(mm)     Snowfall (cm)    \n Min.   :0.0000          Min.   : 0.0000   Min.   :0.00000  \n 1st Qu.:0.0000          1st Qu.: 0.0000   1st Qu.:0.00000  \n Median :0.0100          Median : 0.0000   Median :0.00000  \n Mean   :0.5691          Mean   : 0.1487   Mean   :0.07507  \n 3rd Qu.:0.9300          3rd Qu.: 0.0000   3rd Qu.:0.00000  \n Max.   :3.5200          Max.   :35.0000   Max.   :8.80000  \n\n# Obtained a list of unique levels/values for each categorical variable\nas.list(unique(bikes$Date))\n\n[[1]]\n[1] \"01/12/2017\"\n\n[[2]]\n[1] \"02/12/2017\"\n\n[[3]]\n[1] \"03/12/2017\"\n\n[[4]]\n[1] \"04/12/2017\"\n\n[[5]]\n[1] \"05/12/2017\"\n\n[[6]]\n[1] \"06/12/2017\"\n\n[[7]]\n[1] \"07/12/2017\"\n\n[[8]]\n[1] \"08/12/2017\"\n\n[[9]]\n[1] \"09/12/2017\"\n\n[[10]]\n[1] \"10/12/2017\"\n\n[[11]]\n[1] \"11/12/2017\"\n\n[[12]]\n[1] \"12/12/2017\"\n\n[[13]]\n[1] \"13/12/2017\"\n\n[[14]]\n[1] \"14/12/2017\"\n\n[[15]]\n[1] \"15/12/2017\"\n\n[[16]]\n[1] \"16/12/2017\"\n\n[[17]]\n[1] \"17/12/2017\"\n\n[[18]]\n[1] \"18/12/2017\"\n\n[[19]]\n[1] \"19/12/2017\"\n\n[[20]]\n[1] \"20/12/2017\"\n\n[[21]]\n[1] \"21/12/2017\"\n\n[[22]]\n[1] \"22/12/2017\"\n\n[[23]]\n[1] \"23/12/2017\"\n\n[[24]]\n[1] \"24/12/2017\"\n\n[[25]]\n[1] \"25/12/2017\"\n\n[[26]]\n[1] \"26/12/2017\"\n\n[[27]]\n[1] \"27/12/2017\"\n\n[[28]]\n[1] \"28/12/2017\"\n\n[[29]]\n[1] \"29/12/2017\"\n\n[[30]]\n[1] \"30/12/2017\"\n\n[[31]]\n[1] \"31/12/2017\"\n\n[[32]]\n[1] \"01/01/2018\"\n\n[[33]]\n[1] \"02/01/2018\"\n\n[[34]]\n[1] \"03/01/2018\"\n\n[[35]]\n[1] \"04/01/2018\"\n\n[[36]]\n[1] \"05/01/2018\"\n\n[[37]]\n[1] \"06/01/2018\"\n\n[[38]]\n[1] \"07/01/2018\"\n\n[[39]]\n[1] \"08/01/2018\"\n\n[[40]]\n[1] \"09/01/2018\"\n\n[[41]]\n[1] \"10/01/2018\"\n\n[[42]]\n[1] \"11/01/2018\"\n\n[[43]]\n[1] \"12/01/2018\"\n\n[[44]]\n[1] \"13/01/2018\"\n\n[[45]]\n[1] \"14/01/2018\"\n\n[[46]]\n[1] \"15/01/2018\"\n\n[[47]]\n[1] \"16/01/2018\"\n\n[[48]]\n[1] \"17/01/2018\"\n\n[[49]]\n[1] \"18/01/2018\"\n\n[[50]]\n[1] \"19/01/2018\"\n\n[[51]]\n[1] \"20/01/2018\"\n\n[[52]]\n[1] \"21/01/2018\"\n\n[[53]]\n[1] \"22/01/2018\"\n\n[[54]]\n[1] \"23/01/2018\"\n\n[[55]]\n[1] \"24/01/2018\"\n\n[[56]]\n[1] \"25/01/2018\"\n\n[[57]]\n[1] \"26/01/2018\"\n\n[[58]]\n[1] \"27/01/2018\"\n\n[[59]]\n[1] \"28/01/2018\"\n\n[[60]]\n[1] \"29/01/2018\"\n\n[[61]]\n[1] \"30/01/2018\"\n\n[[62]]\n[1] \"31/01/2018\"\n\n[[63]]\n[1] \"01/02/2018\"\n\n[[64]]\n[1] \"02/02/2018\"\n\n[[65]]\n[1] \"03/02/2018\"\n\n[[66]]\n[1] \"04/02/2018\"\n\n[[67]]\n[1] \"05/02/2018\"\n\n[[68]]\n[1] \"06/02/2018\"\n\n[[69]]\n[1] \"07/02/2018\"\n\n[[70]]\n[1] \"08/02/2018\"\n\n[[71]]\n[1] \"09/02/2018\"\n\n[[72]]\n[1] \"10/02/2018\"\n\n[[73]]\n[1] \"11/02/2018\"\n\n[[74]]\n[1] \"12/02/2018\"\n\n[[75]]\n[1] \"13/02/2018\"\n\n[[76]]\n[1] \"14/02/2018\"\n\n[[77]]\n[1] \"15/02/2018\"\n\n[[78]]\n[1] \"16/02/2018\"\n\n[[79]]\n[1] \"17/02/2018\"\n\n[[80]]\n[1] \"18/02/2018\"\n\n[[81]]\n[1] \"19/02/2018\"\n\n[[82]]\n[1] \"20/02/2018\"\n\n[[83]]\n[1] \"21/02/2018\"\n\n[[84]]\n[1] \"22/02/2018\"\n\n[[85]]\n[1] \"23/02/2018\"\n\n[[86]]\n[1] \"24/02/2018\"\n\n[[87]]\n[1] \"25/02/2018\"\n\n[[88]]\n[1] \"26/02/2018\"\n\n[[89]]\n[1] \"27/02/2018\"\n\n[[90]]\n[1] \"28/02/2018\"\n\n[[91]]\n[1] \"01/03/2018\"\n\n[[92]]\n[1] \"02/03/2018\"\n\n[[93]]\n[1] \"03/03/2018\"\n\n[[94]]\n[1] \"04/03/2018\"\n\n[[95]]\n[1] \"05/03/2018\"\n\n[[96]]\n[1] \"06/03/2018\"\n\n[[97]]\n[1] \"07/03/2018\"\n\n[[98]]\n[1] \"08/03/2018\"\n\n[[99]]\n[1] \"09/03/2018\"\n\n[[100]]\n[1] \"10/03/2018\"\n\n[[101]]\n[1] \"11/03/2018\"\n\n[[102]]\n[1] \"12/03/2018\"\n\n[[103]]\n[1] \"13/03/2018\"\n\n[[104]]\n[1] \"14/03/2018\"\n\n[[105]]\n[1] \"15/03/2018\"\n\n[[106]]\n[1] \"16/03/2018\"\n\n[[107]]\n[1] \"17/03/2018\"\n\n[[108]]\n[1] \"18/03/2018\"\n\n[[109]]\n[1] \"19/03/2018\"\n\n[[110]]\n[1] \"20/03/2018\"\n\n[[111]]\n[1] \"21/03/2018\"\n\n[[112]]\n[1] \"22/03/2018\"\n\n[[113]]\n[1] \"23/03/2018\"\n\n[[114]]\n[1] \"24/03/2018\"\n\n[[115]]\n[1] \"25/03/2018\"\n\n[[116]]\n[1] \"26/03/2018\"\n\n[[117]]\n[1] \"27/03/2018\"\n\n[[118]]\n[1] \"28/03/2018\"\n\n[[119]]\n[1] \"29/03/2018\"\n\n[[120]]\n[1] \"30/03/2018\"\n\n[[121]]\n[1] \"31/03/2018\"\n\n[[122]]\n[1] \"01/04/2018\"\n\n[[123]]\n[1] \"02/04/2018\"\n\n[[124]]\n[1] \"03/04/2018\"\n\n[[125]]\n[1] \"04/04/2018\"\n\n[[126]]\n[1] \"05/04/2018\"\n\n[[127]]\n[1] \"06/04/2018\"\n\n[[128]]\n[1] \"07/04/2018\"\n\n[[129]]\n[1] \"08/04/2018\"\n\n[[130]]\n[1] \"09/04/2018\"\n\n[[131]]\n[1] \"10/04/2018\"\n\n[[132]]\n[1] \"11/04/2018\"\n\n[[133]]\n[1] \"12/04/2018\"\n\n[[134]]\n[1] \"13/04/2018\"\n\n[[135]]\n[1] \"14/04/2018\"\n\n[[136]]\n[1] \"15/04/2018\"\n\n[[137]]\n[1] \"16/04/2018\"\n\n[[138]]\n[1] \"17/04/2018\"\n\n[[139]]\n[1] \"18/04/2018\"\n\n[[140]]\n[1] \"19/04/2018\"\n\n[[141]]\n[1] \"20/04/2018\"\n\n[[142]]\n[1] \"21/04/2018\"\n\n[[143]]\n[1] \"22/04/2018\"\n\n[[144]]\n[1] \"23/04/2018\"\n\n[[145]]\n[1] \"24/04/2018\"\n\n[[146]]\n[1] \"25/04/2018\"\n\n[[147]]\n[1] \"26/04/2018\"\n\n[[148]]\n[1] \"27/04/2018\"\n\n[[149]]\n[1] \"28/04/2018\"\n\n[[150]]\n[1] \"29/04/2018\"\n\n[[151]]\n[1] \"30/04/2018\"\n\n[[152]]\n[1] \"01/05/2018\"\n\n[[153]]\n[1] \"02/05/2018\"\n\n[[154]]\n[1] \"03/05/2018\"\n\n[[155]]\n[1] \"04/05/2018\"\n\n[[156]]\n[1] \"05/05/2018\"\n\n[[157]]\n[1] \"06/05/2018\"\n\n[[158]]\n[1] \"07/05/2018\"\n\n[[159]]\n[1] \"08/05/2018\"\n\n[[160]]\n[1] \"09/05/2018\"\n\n[[161]]\n[1] \"10/05/2018\"\n\n[[162]]\n[1] \"11/05/2018\"\n\n[[163]]\n[1] \"12/05/2018\"\n\n[[164]]\n[1] \"13/05/2018\"\n\n[[165]]\n[1] \"14/05/2018\"\n\n[[166]]\n[1] \"15/05/2018\"\n\n[[167]]\n[1] \"16/05/2018\"\n\n[[168]]\n[1] \"17/05/2018\"\n\n[[169]]\n[1] \"18/05/2018\"\n\n[[170]]\n[1] \"19/05/2018\"\n\n[[171]]\n[1] \"20/05/2018\"\n\n[[172]]\n[1] \"21/05/2018\"\n\n[[173]]\n[1] \"22/05/2018\"\n\n[[174]]\n[1] \"23/05/2018\"\n\n[[175]]\n[1] \"24/05/2018\"\n\n[[176]]\n[1] \"25/05/2018\"\n\n[[177]]\n[1] \"26/05/2018\"\n\n[[178]]\n[1] \"27/05/2018\"\n\n[[179]]\n[1] \"28/05/2018\"\n\n[[180]]\n[1] \"29/05/2018\"\n\n[[181]]\n[1] \"30/05/2018\"\n\n[[182]]\n[1] \"31/05/2018\"\n\n[[183]]\n[1] \"01/06/2018\"\n\n[[184]]\n[1] \"02/06/2018\"\n\n[[185]]\n[1] \"03/06/2018\"\n\n[[186]]\n[1] \"04/06/2018\"\n\n[[187]]\n[1] \"05/06/2018\"\n\n[[188]]\n[1] \"06/06/2018\"\n\n[[189]]\n[1] \"07/06/2018\"\n\n[[190]]\n[1] \"08/06/2018\"\n\n[[191]]\n[1] \"09/06/2018\"\n\n[[192]]\n[1] \"10/06/2018\"\n\n[[193]]\n[1] \"11/06/2018\"\n\n[[194]]\n[1] \"12/06/2018\"\n\n[[195]]\n[1] \"13/06/2018\"\n\n[[196]]\n[1] \"14/06/2018\"\n\n[[197]]\n[1] \"15/06/2018\"\n\n[[198]]\n[1] \"16/06/2018\"\n\n[[199]]\n[1] \"17/06/2018\"\n\n[[200]]\n[1] \"18/06/2018\"\n\n[[201]]\n[1] \"19/06/2018\"\n\n[[202]]\n[1] \"20/06/2018\"\n\n[[203]]\n[1] \"21/06/2018\"\n\n[[204]]\n[1] \"22/06/2018\"\n\n[[205]]\n[1] \"23/06/2018\"\n\n[[206]]\n[1] \"24/06/2018\"\n\n[[207]]\n[1] \"25/06/2018\"\n\n[[208]]\n[1] \"26/06/2018\"\n\n[[209]]\n[1] \"27/06/2018\"\n\n[[210]]\n[1] \"28/06/2018\"\n\n[[211]]\n[1] \"29/06/2018\"\n\n[[212]]\n[1] \"30/06/2018\"\n\n[[213]]\n[1] \"01/07/2018\"\n\n[[214]]\n[1] \"02/07/2018\"\n\n[[215]]\n[1] \"03/07/2018\"\n\n[[216]]\n[1] \"04/07/2018\"\n\n[[217]]\n[1] \"05/07/2018\"\n\n[[218]]\n[1] \"06/07/2018\"\n\n[[219]]\n[1] \"07/07/2018\"\n\n[[220]]\n[1] \"08/07/2018\"\n\n[[221]]\n[1] \"09/07/2018\"\n\n[[222]]\n[1] \"10/07/2018\"\n\n[[223]]\n[1] \"11/07/2018\"\n\n[[224]]\n[1] \"12/07/2018\"\n\n[[225]]\n[1] \"13/07/2018\"\n\n[[226]]\n[1] \"14/07/2018\"\n\n[[227]]\n[1] \"15/07/2018\"\n\n[[228]]\n[1] \"16/07/2018\"\n\n[[229]]\n[1] \"17/07/2018\"\n\n[[230]]\n[1] \"18/07/2018\"\n\n[[231]]\n[1] \"19/07/2018\"\n\n[[232]]\n[1] \"20/07/2018\"\n\n[[233]]\n[1] \"21/07/2018\"\n\n[[234]]\n[1] \"22/07/2018\"\n\n[[235]]\n[1] \"23/07/2018\"\n\n[[236]]\n[1] \"24/07/2018\"\n\n[[237]]\n[1] \"25/07/2018\"\n\n[[238]]\n[1] \"26/07/2018\"\n\n[[239]]\n[1] \"27/07/2018\"\n\n[[240]]\n[1] \"28/07/2018\"\n\n[[241]]\n[1] \"29/07/2018\"\n\n[[242]]\n[1] \"30/07/2018\"\n\n[[243]]\n[1] \"31/07/2018\"\n\n[[244]]\n[1] \"01/08/2018\"\n\n[[245]]\n[1] \"02/08/2018\"\n\n[[246]]\n[1] \"03/08/2018\"\n\n[[247]]\n[1] \"04/08/2018\"\n\n[[248]]\n[1] \"05/08/2018\"\n\n[[249]]\n[1] \"06/08/2018\"\n\n[[250]]\n[1] \"07/08/2018\"\n\n[[251]]\n[1] \"08/08/2018\"\n\n[[252]]\n[1] \"09/08/2018\"\n\n[[253]]\n[1] \"10/08/2018\"\n\n[[254]]\n[1] \"11/08/2018\"\n\n[[255]]\n[1] \"12/08/2018\"\n\n[[256]]\n[1] \"13/08/2018\"\n\n[[257]]\n[1] \"14/08/2018\"\n\n[[258]]\n[1] \"15/08/2018\"\n\n[[259]]\n[1] \"16/08/2018\"\n\n[[260]]\n[1] \"17/08/2018\"\n\n[[261]]\n[1] \"18/08/2018\"\n\n[[262]]\n[1] \"19/08/2018\"\n\n[[263]]\n[1] \"20/08/2018\"\n\n[[264]]\n[1] \"21/08/2018\"\n\n[[265]]\n[1] \"22/08/2018\"\n\n[[266]]\n[1] \"23/08/2018\"\n\n[[267]]\n[1] \"24/08/2018\"\n\n[[268]]\n[1] \"25/08/2018\"\n\n[[269]]\n[1] \"26/08/2018\"\n\n[[270]]\n[1] \"27/08/2018\"\n\n[[271]]\n[1] \"28/08/2018\"\n\n[[272]]\n[1] \"29/08/2018\"\n\n[[273]]\n[1] \"30/08/2018\"\n\n[[274]]\n[1] \"31/08/2018\"\n\n[[275]]\n[1] \"01/09/2018\"\n\n[[276]]\n[1] \"02/09/2018\"\n\n[[277]]\n[1] \"03/09/2018\"\n\n[[278]]\n[1] \"04/09/2018\"\n\n[[279]]\n[1] \"05/09/2018\"\n\n[[280]]\n[1] \"06/09/2018\"\n\n[[281]]\n[1] \"07/09/2018\"\n\n[[282]]\n[1] \"08/09/2018\"\n\n[[283]]\n[1] \"09/09/2018\"\n\n[[284]]\n[1] \"10/09/2018\"\n\n[[285]]\n[1] \"11/09/2018\"\n\n[[286]]\n[1] \"12/09/2018\"\n\n[[287]]\n[1] \"13/09/2018\"\n\n[[288]]\n[1] \"14/09/2018\"\n\n[[289]]\n[1] \"15/09/2018\"\n\n[[290]]\n[1] \"16/09/2018\"\n\n[[291]]\n[1] \"17/09/2018\"\n\n[[292]]\n[1] \"18/09/2018\"\n\n[[293]]\n[1] \"19/09/2018\"\n\n[[294]]\n[1] \"20/09/2018\"\n\n[[295]]\n[1] \"21/09/2018\"\n\n[[296]]\n[1] \"22/09/2018\"\n\n[[297]]\n[1] \"23/09/2018\"\n\n[[298]]\n[1] \"24/09/2018\"\n\n[[299]]\n[1] \"25/09/2018\"\n\n[[300]]\n[1] \"26/09/2018\"\n\n[[301]]\n[1] \"27/09/2018\"\n\n[[302]]\n[1] \"28/09/2018\"\n\n[[303]]\n[1] \"29/09/2018\"\n\n[[304]]\n[1] \"30/09/2018\"\n\n[[305]]\n[1] \"01/10/2018\"\n\n[[306]]\n[1] \"02/10/2018\"\n\n[[307]]\n[1] \"03/10/2018\"\n\n[[308]]\n[1] \"04/10/2018\"\n\n[[309]]\n[1] \"05/10/2018\"\n\n[[310]]\n[1] \"06/10/2018\"\n\n[[311]]\n[1] \"07/10/2018\"\n\n[[312]]\n[1] \"08/10/2018\"\n\n[[313]]\n[1] \"09/10/2018\"\n\n[[314]]\n[1] \"10/10/2018\"\n\n[[315]]\n[1] \"11/10/2018\"\n\n[[316]]\n[1] \"12/10/2018\"\n\n[[317]]\n[1] \"13/10/2018\"\n\n[[318]]\n[1] \"14/10/2018\"\n\n[[319]]\n[1] \"15/10/2018\"\n\n[[320]]\n[1] \"16/10/2018\"\n\n[[321]]\n[1] \"17/10/2018\"\n\n[[322]]\n[1] \"18/10/2018\"\n\n[[323]]\n[1] \"19/10/2018\"\n\n[[324]]\n[1] \"20/10/2018\"\n\n[[325]]\n[1] \"21/10/2018\"\n\n[[326]]\n[1] \"22/10/2018\"\n\n[[327]]\n[1] \"23/10/2018\"\n\n[[328]]\n[1] \"24/10/2018\"\n\n[[329]]\n[1] \"25/10/2018\"\n\n[[330]]\n[1] \"26/10/2018\"\n\n[[331]]\n[1] \"27/10/2018\"\n\n[[332]]\n[1] \"28/10/2018\"\n\n[[333]]\n[1] \"29/10/2018\"\n\n[[334]]\n[1] \"30/10/2018\"\n\n[[335]]\n[1] \"31/10/2018\"\n\n[[336]]\n[1] \"01/11/2018\"\n\n[[337]]\n[1] \"02/11/2018\"\n\n[[338]]\n[1] \"03/11/2018\"\n\n[[339]]\n[1] \"04/11/2018\"\n\n[[340]]\n[1] \"05/11/2018\"\n\n[[341]]\n[1] \"06/11/2018\"\n\n[[342]]\n[1] \"07/11/2018\"\n\n[[343]]\n[1] \"08/11/2018\"\n\n[[344]]\n[1] \"09/11/2018\"\n\n[[345]]\n[1] \"10/11/2018\"\n\n[[346]]\n[1] \"11/11/2018\"\n\n[[347]]\n[1] \"12/11/2018\"\n\n[[348]]\n[1] \"13/11/2018\"\n\n[[349]]\n[1] \"14/11/2018\"\n\n[[350]]\n[1] \"15/11/2018\"\n\n[[351]]\n[1] \"16/11/2018\"\n\n[[352]]\n[1] \"17/11/2018\"\n\n[[353]]\n[1] \"18/11/2018\"\n\n[[354]]\n[1] \"19/11/2018\"\n\n[[355]]\n[1] \"20/11/2018\"\n\n[[356]]\n[1] \"21/11/2018\"\n\n[[357]]\n[1] \"22/11/2018\"\n\n[[358]]\n[1] \"23/11/2018\"\n\n[[359]]\n[1] \"24/11/2018\"\n\n[[360]]\n[1] \"25/11/2018\"\n\n[[361]]\n[1] \"26/11/2018\"\n\n[[362]]\n[1] \"27/11/2018\"\n\n[[363]]\n[1] \"28/11/2018\"\n\n[[364]]\n[1] \"29/11/2018\"\n\n[[365]]\n[1] \"30/11/2018\"\n\nas.list(unique(bikes$Seasons))\n\n[[1]]\n[1] \"Winter\"\n\n[[2]]\n[1] \"Spring\"\n\n[[3]]\n[1] \"Summer\"\n\n[[4]]\n[1] \"Autumn\"\n\nas.list(unique(bikes$Holiday))\n\n[[1]]\n[1] \"No Holiday\"\n\n[[2]]\n[1] \"Holiday\"\n\nas.list(unique(bikes$'Functioning Day'))\n\n[[1]]\n[1] \"Yes\"\n\n[[2]]\n[1] \"No\"\n\n\n\n\nNext we’ll convert the Date column into month/day/year to more easily read and viewed the data set.\n\n\n\n# Using lubridate, we're reformmating the date to be m/d/y. First we use as.Date to parse the dates and allow them to be readable in R then we reformat them as m/d/y.\nbikes &lt;- bikes %&gt;%\n  mutate(Date = dmy(Date))\n\n\n\nNow we’re going to change the categorical variables to have a class of factor. This’ll allow us to use the factors/levels of these variables in statistical modeling for us to better understand how these different levels are affected.\n\n\n\n# Used mutate to change the categorical variable class characters to factors.\n\nbikes &lt;- bikes %&gt;%\n  mutate(Seasons = as.factor(Seasons),\n         Holiday = as.factor(Holiday),\n         `Functioning Day` = as.factor(`Functioning Day`))\n\n\n\nLast, we’re going rename all of the variables to have easy names to reference. Using the clean_names function, this’ll make it easier for us to reference in our later queries due to the universal naming convention.\n\n\n\n# Used clean_names function from the janitor package to lowercase and insert '_' names for all columns. \nbikes &lt;- bikes %&gt;%\n  clean_names()\n\n\n\nNow that our data is clean up, we’re going to create summary statistics about bike rental count across our categorical variables. When creating the first summary statistics for bike rentals, bike functioning day that equaled no contained no information to find a statistic on because no bikes were rented on those days. As a result, we created another summary filtering to only keep where bike functioning day equaled to yes.\n\n\n\n# Created a bike rental summary grouped by seasons, holiday, and functioning_day\nbike_rental_summary &lt;- bikes %&gt;%\n  group_by(seasons, holiday, functioning_day) %&gt;%\n  summarise(bike_rental_min = min(rented_bike_count),\n               bike_rental_median = median(rented_bike_count),\n               bike_rental_max = max(rented_bike_count),\n               bike_rental_mean = mean(rented_bike_count),\n               bike_rental_sd = sd(rented_bike_count))\nbike_rental_summary\n\n# A tibble: 11 × 8\n# Groups:   seasons, holiday [8]\n   seasons holiday    functioning_day bike_rental_min bike_rental_median\n   &lt;fct&gt;   &lt;fct&gt;      &lt;fct&gt;                     &lt;dbl&gt;              &lt;dbl&gt;\n 1 Autumn  Holiday    No                            0                 0 \n 2 Autumn  Holiday    Yes                         105               900 \n 3 Autumn  No Holiday No                            0                 0 \n 4 Autumn  No Holiday Yes                           2               852 \n 5 Spring  Holiday    Yes                          11               366.\n 6 Spring  No Holiday No                            0                 0 \n 7 Spring  No Holiday Yes                           2               605 \n 8 Summer  Holiday    Yes                         218               925 \n 9 Summer  No Holiday Yes                           9               904.\n10 Winter  Holiday    Yes                           3               138 \n11 Winter  No Holiday Yes                           7               212 \n# ℹ 3 more variables: bike_rental_max &lt;dbl&gt;, bike_rental_mean &lt;dbl&gt;,\n#   bike_rental_sd &lt;dbl&gt;\n\n# Further subsetted where functioning day is yes\nbike_rental_summary_functional &lt;- bikes %&gt;%\n  filter(functioning_day == \"Yes\") %&gt;%\n  group_by(seasons, holiday, functioning_day) %&gt;%\n  summarise(bike_rental_min = min(rented_bike_count),\n               bike_rental_median = median(rented_bike_count),\n               bike_rental_max = max(rented_bike_count),\n               bike_rental_mean = mean(rented_bike_count),\n               bike_rental_sd = sd(rented_bike_count))\nbike_rental_summary_functional\n\n# A tibble: 8 × 8\n# Groups:   seasons, holiday [8]\n  seasons holiday    functioning_day bike_rental_min bike_rental_median\n  &lt;fct&gt;   &lt;fct&gt;      &lt;fct&gt;                     &lt;dbl&gt;              &lt;dbl&gt;\n1 Autumn  Holiday    Yes                         105               900 \n2 Autumn  No Holiday Yes                           2               852 \n3 Spring  Holiday    Yes                          11               366.\n4 Spring  No Holiday Yes                           2               605 \n5 Summer  Holiday    Yes                         218               925 \n6 Summer  No Holiday Yes                           9               904.\n7 Winter  Holiday    Yes                           3               138 \n8 Winter  No Holiday Yes                           7               212 \n# ℹ 3 more variables: bike_rental_max &lt;dbl&gt;, bike_rental_mean &lt;dbl&gt;,\n#   bike_rental_sd &lt;dbl&gt;\n\n\n\n\nIn order to simplify our previous analysis and initial bikes data set, we’re going to summarize across the hours so each day has one observation associated with it along with each weather condition. We’ll do this by summing up the total amount of bikes rented per hour per day to return This daily rental summary gives us a much better grasp of daily statistics compared to the initial bike data which filtered the data per each hour of the day for bike rentals, whereas this new summary combines all of those hour values into one day to give us a total amount of bikes rented per day. We continue to filter by a functioning day of yes so it doesn’t skew our summary of statistics regarding bike rental data and the rest of the numerical variables. Additionally, when filtering out functioning day ‘No’, the total data goes from 365 days to 353 days indicating that there were 12 days that no bikes were rented out to people.\n\n\n\ndaily_rental_summary &lt;- bikes %&gt;%\n  filter(functioning_day == \"Yes\") %&gt;%\n  group_by(date, seasons, holiday) %&gt;%\n  summarise(bike_count_sum = sum(rented_bike_count),\n               rainfall_mm_sum = sum(rainfall_mm),\n               snowfall_cm_sum = sum(snowfall_cm),\n               temperature_c_mean = mean(temperature_c),\n               humidity_percent_mean = mean(humidity_percent),\n               wind_speed_mean = mean(wind_speed_m_s),\n               visibility_mean = mean(visibility_10m),\n               dew_point_temp_c_mean = mean(dew_point_temperature_c),\n               solar_radiation_mean = mean(solar_radiation_mj_m2),\n               rainfall_mm_mean = mean(rainfall_mm),\n               snowfall_cm_mean = mean(snowfall_cm))\ndaily_rental_summary\n\n# A tibble: 353 × 14\n# Groups:   date, seasons [353]\n   date       seasons holiday    bike_count_sum rainfall_mm_sum snowfall_cm_sum\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;               &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;\n 1 2017-12-01 Winter  No Holiday           9539             0               0  \n 2 2017-12-02 Winter  No Holiday           8523             0               0  \n 3 2017-12-03 Winter  No Holiday           7222             4               0  \n 4 2017-12-04 Winter  No Holiday           8729             0.1             0  \n 5 2017-12-05 Winter  No Holiday           8307             0               0  \n 6 2017-12-06 Winter  No Holiday           6669             1.3             8.6\n 7 2017-12-07 Winter  No Holiday           8549             0              10.4\n 8 2017-12-08 Winter  No Holiday           8032             0               0  \n 9 2017-12-09 Winter  No Holiday           7233             0               0  \n10 2017-12-10 Winter  No Holiday           3453             4.1            32.5\n# ℹ 343 more rows\n# ℹ 8 more variables: temperature_c_mean &lt;dbl&gt;, humidity_percent_mean &lt;dbl&gt;,\n#   wind_speed_mean &lt;dbl&gt;, visibility_mean &lt;dbl&gt;, dew_point_temp_c_mean &lt;dbl&gt;,\n#   solar_radiation_mean &lt;dbl&gt;, rainfall_mm_mean &lt;dbl&gt;, snowfall_cm_mean &lt;dbl&gt;\n\n\n\n\nNow with this new analysis, we’re going to create a summary statistic of our daily rental summary to explore some data. As seen below, there are a total of 353 observations, denoted by ‘date’ in this data set. Of those dates 81 of them are from the Autumn, 90 from the Winter, 90 from the Spring, and 92 from the Summer. Out of the 353 days, 17 of those days are defined as holidays and 336 are not considered holidays. There’s a handful of data to go through for the weather conditions, but we’ll create a correlation matrix and some plots below to explore those.\n\n\n\n# Created a summary statistics for the daily_rental_summary\nsummary(daily_rental_summary)\n\n      date              seasons         holiday    bike_count_sum \n Min.   :2017-12-01   Autumn:81   Holiday   : 17   Min.   :  977  \n 1st Qu.:2018-02-27   Spring:90   No Holiday:336   1st Qu.: 6967  \n Median :2018-05-28   Summer:92                    Median :18563  \n Mean   :2018-05-28   Winter:90                    Mean   :17485  \n 3rd Qu.:2018-08-24                                3rd Qu.:26285  \n Max.   :2018-11-30                                Max.   :36149  \n rainfall_mm_sum  snowfall_cm_sum  temperature_c_mean humidity_percent_mean\n Min.   : 0.000   Min.   : 0.000   Min.   :-14.738    Min.   :22.25        \n 1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.:  3.304    1st Qu.:47.58        \n Median : 0.000   Median : 0.000   Median : 13.738    Median :57.17        \n Mean   : 3.576   Mean   : 1.863   Mean   : 12.776    Mean   :58.17        \n 3rd Qu.: 0.500   3rd Qu.: 0.000   3rd Qu.: 22.592    3rd Qu.:67.71        \n Max.   :95.500   Max.   :78.700   Max.   : 33.742    Max.   :95.88        \n wind_speed_mean  visibility_mean  dew_point_temp_c_mean solar_radiation_mean\n Min.   :0.6625   Min.   : 214.3   Min.   :-27.750       Min.   :0.02917     \n 1st Qu.:1.3042   1st Qu.:1087.0   1st Qu.: -5.188       1st Qu.:0.28333     \n Median :1.6583   Median :1557.8   Median :  4.612       Median :0.56500     \n Mean   :1.7261   Mean   :1434.0   Mean   :  3.954       Mean   :0.56773     \n 3rd Qu.:1.9542   3rd Qu.:1874.3   3rd Qu.: 14.921       3rd Qu.:0.82000     \n Max.   :4.0000   Max.   :2000.0   Max.   : 25.038       Max.   :1.21667     \n rainfall_mm_mean  snowfall_cm_mean \n Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.00000   Median :0.00000  \n Mean   :0.15072   Mean   :0.07762  \n 3rd Qu.:0.02083   3rd Qu.:0.00000  \n Max.   :3.97917   Max.   :3.27917  \n\n\n\nBelow I have created the first plot, a scatter plot to look at the relationship between bike count rentals and temperature across seasons. The plot shows a strong positive correlation between these two variables, as one variable increases, the other increases. As temperature increases, bike rentals also increases. There are a cluster of data points where the temperature is below 10 degrees celcius with under 10,000 bike rentals per day; those data points most likely represent days colder days with potential less favorable biking conditions, as seen, denoted by the winter data points. Then there is a cluster of data points from 20 to 25 degrees celcius with more than 30,000 bike rentals a day; that cluster represents and shows that perhaps bike riders enjoy more warm weather, denoted by a mix of the Spring, Autumn, and Summer data points. Additionally, the data points are much more spread from 10 to 30 degrees celcius, perhaps indicating that people enjoy riding in more warm weather. However, there are also days where the temperatures are higher but bike rentals are low… this could be due to other weather conditions like some rainfall, wind speeds, holidays, etc.\n\n\n# Created a scatterplot to explore\nscatter_plot &lt;- ggplot(daily_rental_summary,\n                    aes(x = temperature_c_mean, y = bike_count_sum, color = seasons)) +\n                  geom_jitter(width = 0.2, alpha = 0.6) +\n                  ggtitle(label = \"The Relationship between Bike Count Rental \\n and Temperature (C) across Seasons\",\n                          subtitle = \"Scatter Plot\") +\n                  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n                        plot.subtitle = element_text(hjust = 0.5)) +\n                  labs(x = \"Temperature \\n (in Celcius)\", \n                       y = \"Bike Rentals \\n (bikes rented per day)\") +\n                  scale_fill_discrete(\"Temperature\")\nscatter_plot\n\n\n\n\n\n\n\n\n\nFor biking novices like myself, weather conditions that affect biking such as rainfall, snowfall, etc. are apparent, which is I’m interested in how visibility may affect bike rentals. Below I have created a plot between visibility and bike rentals across seasons and faceted by holidays. Upon observation there is a slight positive correlation on non-holidays with more rentals based on more visibility. For the holiday facet, there is not much of a pattern with rentals being spread across the entire range of visibility perhaps showcasing that visibility doesn’t affect bike rental rate as much on holidays. When looking at both holiday and non-holiday data, Summer and Autumn months produce a higher number of bike rentals compared to Winter and Spring months. Summer months show the highest number of rentals on non-holidays from 500m to 2,000m indicating that summer weather encourages biking regardless of the visibility. In conclusion, the higher the visibility, the more bike rentals there are as the plots showcase a strong positive relationship between the two variables.\n\n\nfacet_plot &lt;- ggplot(daily_rental_summary,\n                    aes(x = visibility_mean, y = bike_count_sum, color = seasons)) + \n                  geom_jitter(width = 0.2, alpha = 0.6) +\n                  facet_wrap(~ holiday) +\n                  ggtitle(label = \"The Relationship between Bike Count Rental \\n and Visibility (by 10m) across Seasons with Holiday facet\",\n                          subtitle = \"Scatter Plot\") +\n                  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n                        plot.subtitle = element_text(hjust = 0.5)) +\n                  labs(x = \"Visibility \\n (by 10m)\", \n                       y = \"Bike Rentals \\n (bikes rented per day)\")\nfacet_plot\n\n\n\n\n\n\n\n\n\nNext is the reported correlation matrix for all of the numeric variables; since there are so many, I will pick and choose a handful of correlations (relationship between variables) related to bike_count_sum to explore. Looking at bike_count_sum and its correlations in the first column, we can see that there are some strong positive correlations (as one variable increases, the other also increases), mainly bike_count_sum and temperature with a correlation of 0.753 and bike_count_sum and solar_radiation with a correlation of 0.736. From the first observation, we can see that higher temperatures are associated with a higher number of bike rentals; bike riders enjoy good weather and warmer temperatures when riding bikes. This supported our first scatterplot as we a strong positive correlation from the plot. The second correlation shows that higher solar radiation, i.e. more sun, also correlates with more bike rentals. Additionally, there are many weak negative correlations (as one variable increases, the other one one decreases) with bike_count such as: wind_speed_mean (-0.193), rainfall_mm_mean (-0.237), and snowfall_mm_mean (-0.265). Bike rental counts are expected to be negatively associated with these weather variables because high wind speeds, rainfall, and snowfall affect biking conditions and enviroments, and as a result tend to reduce bike rental rates.\n\n\n# Created a filtered data frame to only show numeric variables to create correlation matrix\nnumeric_daily_rental_summary &lt;- daily_rental_summary %&gt;%\n  ungroup() %&gt;%\n  select(where(is.numeric)) \nnumeric_daily_rental_summary\n\n# A tibble: 353 × 11\n   bike_count_sum rainfall_mm_sum snowfall_cm_sum temperature_c_mean\n            &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;              &lt;dbl&gt;\n 1           9539             0               0              -2.45  \n 2           8523             0               0               1.32  \n 3           7222             4               0               4.88  \n 4           8729             0.1             0              -0.304 \n 5           8307             0               0              -4.46  \n 6           6669             1.3             8.6             0.0458\n 7           8549             0              10.4             1.09  \n 8           8032             0               0              -3.82  \n 9           7233             0               0              -0.846 \n10           3453             4.1            32.5             1.19  \n# ℹ 343 more rows\n# ℹ 7 more variables: humidity_percent_mean &lt;dbl&gt;, wind_speed_mean &lt;dbl&gt;,\n#   visibility_mean &lt;dbl&gt;, dew_point_temp_c_mean &lt;dbl&gt;,\n#   solar_radiation_mean &lt;dbl&gt;, rainfall_mm_mean &lt;dbl&gt;, snowfall_cm_mean &lt;dbl&gt;\n\n# Referenced previously created filtered data frame to create a correlation matrix between all of the numeric variables\nnum_cor_matrix &lt;- numeric_daily_rental_summary %&gt;%\n  cor()\nnum_cor_matrix\n\n                      bike_count_sum rainfall_mm_sum snowfall_cm_sum\nbike_count_sum            1.00000000     -0.23910905     -0.26529110\nrainfall_mm_sum          -0.23910905      1.00000000     -0.02313404\nsnowfall_cm_sum          -0.26529110     -0.02313404      1.00000000\ntemperature_c_mean        0.75307673      0.14451727     -0.26696366\nhumidity_percent_mean     0.03588697      0.52864263      0.06539191\nwind_speed_mean          -0.19288142     -0.10167578      0.02088156\nvisibility_mean           0.16599375     -0.22199387     -0.10188902\ndew_point_temp_c_mean     0.65047655      0.26456621     -0.20955286\nsolar_radiation_mean      0.73589290     -0.32270413     -0.23343056\nrainfall_mm_mean         -0.23686365      0.99791474     -0.02360438\nsnowfall_cm_mean         -0.26529110     -0.02313404      1.00000000\n                      temperature_c_mean humidity_percent_mean wind_speed_mean\nbike_count_sum               0.753076732            0.03588697     -0.19288142\nrainfall_mm_sum              0.144517274            0.52864263     -0.10167578\nsnowfall_cm_sum             -0.266963662            0.06539191      0.02088156\ntemperature_c_mean           1.000000000            0.40416749     -0.26072179\nhumidity_percent_mean        0.404167486            1.00000000     -0.23425778\nwind_speed_mean             -0.260721792           -0.23425778      1.00000000\nvisibility_mean              0.002336683           -0.55917733      0.20602264\ndew_point_temp_c_mean        0.962796255            0.63204729     -0.28770322\nsolar_radiation_mean         0.550274301           -0.27444967      0.09612635\nrainfall_mm_mean             0.144573425            0.52795952     -0.09863450\nsnowfall_cm_mean            -0.266963662            0.06539191      0.02088156\n                      visibility_mean dew_point_temp_c_mean\nbike_count_sum            0.165993749             0.6504765\nrainfall_mm_sum          -0.221993866             0.2645662\nsnowfall_cm_sum          -0.101889019            -0.2095529\ntemperature_c_mean        0.002336683             0.9627963\nhumidity_percent_mean    -0.559177334             0.6320473\nwind_speed_mean           0.206022636            -0.2877032\nvisibility_mean           1.000000000            -0.1535516\ndew_point_temp_c_mean    -0.153551591             1.0000000\nsolar_radiation_mean      0.271395906             0.3831571\nrainfall_mm_mean         -0.218236382             0.2644913\nsnowfall_cm_mean         -0.101889019            -0.2095529\n                      solar_radiation_mean rainfall_mm_mean snowfall_cm_mean\nbike_count_sum                  0.73589290      -0.23686365      -0.26529110\nrainfall_mm_sum                -0.32270413       0.99791474      -0.02313404\nsnowfall_cm_sum                -0.23343056      -0.02360438       1.00000000\ntemperature_c_mean              0.55027430       0.14457343      -0.26696366\nhumidity_percent_mean          -0.27444967       0.52795952       0.06539191\nwind_speed_mean                 0.09612635      -0.09863450       0.02088156\nvisibility_mean                 0.27139591      -0.21823638      -0.10188902\ndew_point_temp_c_mean           0.38315713       0.26449127      -0.20955286\nsolar_radiation_mean            1.00000000      -0.32079734      -0.23343056\nrainfall_mm_mean               -0.32079734       1.00000000      -0.02360438\nsnowfall_cm_mean               -0.23343056      -0.02360438       1.00000000\n\n\n\n\n\n\nFor this next section, we’ll be splitting the data: 75% of the data into the training set and 25% of it into the test set. We’ll also stratify the data by seasons. Additionally, on the training set we’ll create a 10 fold CV split, which randomly splits the data into V groups of roughly equal size (“folds”).\n\n\n# Split the data\nset.seed(123)\nbike_split &lt;- initial_split(daily_rental_summary, prop = 3/4, strata = seasons)\ntrain_data &lt;- training(bike_split)\ntest_data &lt;- testing(bike_split)\n\n\n# Created a 10 fold CV split\ncv_folds_10 &lt;- vfold_cv(data = train_data, v = 10)\n\n\n\n\n\nNow we’re going to work on creating the recipes!\n\n\nFirst recipe!\n\n\nHere we’re going to fix up the date variable a bit, standardize the numeric variables, and create dummy variables for the seasons, holiday, and our new day type!\n\n\n# Creating the first recipe\nrecipe_1 &lt;- recipe(bike_count_sum ~ ., data = train_data) %&gt;%\n  step_date(date, features = \"dow\") %&gt;% # Used to extract day of week\n  step_rm(date) %&gt;%\n  step_mutate(day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) %&gt;% # Creating day_type to categorical variable with 2 levels: weekend and weekday\n  step_rm(date_dow) %&gt;% # Used as a general variable filter \n  # step_rm(dow_day) %&gt;% # Removed the intermediate variable created\n  step_normalize(all_numeric()) %&gt;% # Standardizes all numeric variables\n  step_dummy(seasons, holiday, day_type) # Created dummy variables\n\n\n# Checking recipe\nprep_recipe1 &lt;- recipe_1 %&gt;% \n  prep(training = train_data)\n\nbaked_data1 &lt;- bake(prep_recipe1, new_data = NULL)\n\nhead(baked_data1)\n\n# A tibble: 6 × 16\n  rainfall_mm_sum snowfall_cm_sum temperature_c_mean humidity_percent_mean\n            &lt;dbl&gt;           &lt;dbl&gt;              &lt;dbl&gt;                 &lt;dbl&gt;\n1          -0.297          -0.218              0.943                 0.214\n2          -0.297          -0.218              0.978                 0.818\n3          -0.177          -0.218              0.800                -0.116\n4          -0.297          -0.218              0.760                -0.666\n5          -0.297          -0.218              0.783                -0.613\n6          -0.297          -0.218              0.867                -0.571\n# ℹ 12 more variables: wind_speed_mean &lt;dbl&gt;, visibility_mean &lt;dbl&gt;,\n#   dew_point_temp_c_mean &lt;dbl&gt;, solar_radiation_mean &lt;dbl&gt;,\n#   rainfall_mm_mean &lt;dbl&gt;, snowfall_cm_mean &lt;dbl&gt;, bike_count_sum &lt;dbl&gt;,\n#   seasons_Spring &lt;dbl&gt;, seasons_Summer &lt;dbl&gt;, seasons_Winter &lt;dbl&gt;,\n#   holiday_No.Holiday &lt;dbl&gt;, day_type_weekend &lt;dbl&gt;\n\n\n\nSecond recipe!\n\n\nNow we’re going to follow the same steps as the first recipe and add interactions between seasons and holiday, seasons and temp, temp and rainfall.\n\n\n# Creating the second recipe\nrecipe_2 &lt;- recipe(\"bike_count_sum\" ~ ., data = train_data) %&gt;%\n  step_date(date, features = \"dow\") %&gt;% # Used to extract day of week\n  step_rm(date) %&gt;%\n  step_mutate(day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) %&gt;% # Creating day_type to categorical variable with 2 levels: weekend and weekday\n  step_rm(date_dow) %&gt;% # Used as a general variable filter \n  # step_rm(dow_day) %&gt;% # Removed the intermediate variable created\n  step_normalize(all_numeric()) %&gt;% # Standardizes all numeric variables\n  step_dummy(seasons, holiday, day_type) %&gt;% # Created dummy variables # Created dummy variables\n  step_interact(~ starts_with(\"seasons\"):holiday_No.Holiday) %&gt;% \n                  step_interact(~ starts_with(\"seasons\"):temperature_c_mean) %&gt;% \n                  step_interact(~ temperature_c_mean:rainfall_mm_sum) # Created for the interactions\n\n\n# Checking recipe 2\nprep_recipe2 &lt;- recipe_2 %&gt;% \n  prep(training = train_data)\n\nbaked_data2 &lt;- bake(prep_recipe2, new_data = NULL)\n\nhead(baked_data2)\n\n# A tibble: 6 × 26\n  bike_count_sum rainfall_mm_sum snowfall_cm_sum temperature_c_mean\n           &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;              &lt;dbl&gt;\n1           1.40          -0.297          -0.218              0.943\n2           1.07          -0.297          -0.218              0.978\n3           1.33          -0.177          -0.218              0.800\n4           1.27          -0.297          -0.218              0.760\n5           1.12          -0.297          -0.218              0.783\n6           1.37          -0.297          -0.218              0.867\n# ℹ 22 more variables: humidity_percent_mean &lt;dbl&gt;, wind_speed_mean &lt;dbl&gt;,\n#   visibility_mean &lt;dbl&gt;, dew_point_temp_c_mean &lt;dbl&gt;,\n#   solar_radiation_mean &lt;dbl&gt;, rainfall_mm_mean &lt;dbl&gt;, snowfall_cm_mean &lt;dbl&gt;,\n#   seasons_Spring &lt;dbl&gt;, seasons_Summer &lt;dbl&gt;, seasons_Winter &lt;dbl&gt;,\n#   holiday_No.Holiday &lt;dbl&gt;, day_type_weekend &lt;dbl&gt;,\n#   seasons_Spring_x_holiday_No.Holiday &lt;dbl&gt;,\n#   seasons_Summer_x_holiday_No.Holiday &lt;dbl&gt;, …\n\n\n\nThird recipe!\n\n\nNow we’re going to follow the same steps as the second recipe and add quadratic terms for each numeric predictor\n\n\n# Creating the third recipe\nrecipe_3 &lt;- recipe(bike_count_sum ~ ., data = train_data) %&gt;%\n  step_date(date, features = \"dow\") %&gt;% # Used to extract day of week\n  step_rm(date) %&gt;%\n  step_mutate(day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) %&gt;% # Creating day_type to categorical variable with 2 levels: weekend and weekday\n  step_rm(date_dow) %&gt;% # Used as a general variable filter \n  # step_rm(dow_day) %&gt;% # Removed the intermediate variable created\n  step_normalize(all_numeric()) %&gt;% # Standardizes all numeric variables\n  step_dummy(seasons, holiday, day_type) %&gt;% # Created dummy variables # Created dummy variables\n  step_interact(~ starts_with(\"seasons\"):holiday_No.Holiday) %&gt;% \n                  step_interact(~ starts_with(\"seasons\"):temperature_c_mean) %&gt;% \n                  step_interact(~ temperature_c_mean:rainfall_mm_sum) %&gt;% # Created for the interactions\n  step_poly(rainfall_mm_sum, snowfall_cm_sum, temperature_c_mean, humidity_percent_mean, wind_speed_mean, visibility_mean, dew_point_temp_c_mean, solar_radiation_mean, rainfall_mm_mean, snowfall_cm_mean, degree = 2)\n\n\n# Checking recipe 3\nprep_recipe3 &lt;- recipe_3 %&gt;% \n  prep(training = train_data)\n\nbaked_data3 &lt;- bake(prep_recipe3, new_data = NULL)\n\nhead(baked_data3)\n\n# A tibble: 6 × 36\n  bike_count_sum seasons_Spring seasons_Summer seasons_Winter holiday_No.Holiday\n           &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;              &lt;dbl&gt;\n1           1.40              0              0              0                  1\n2           1.07              0              0              0                  1\n3           1.33              0              0              0                  1\n4           1.27              0              0              0                  1\n5           1.12              0              0              0                  1\n6           1.37              0              0              0                  1\n# ℹ 31 more variables: day_type_weekend &lt;dbl&gt;,\n#   seasons_Spring_x_holiday_No.Holiday &lt;dbl&gt;,\n#   seasons_Summer_x_holiday_No.Holiday &lt;dbl&gt;,\n#   seasons_Winter_x_holiday_No.Holiday &lt;dbl&gt;,\n#   seasons_Spring_x_temperature_c_mean &lt;dbl&gt;,\n#   seasons_Summer_x_temperature_c_mean &lt;dbl&gt;,\n#   seasons_Winter_x_temperature_c_mean &lt;dbl&gt;, …\n\n\n\n\n\n\nNow we set up our linear model to use the lm engine and fit the models accordingly.\n\n\n# Specifying linear model\nbike_lm &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\n# Creating work flows for each recipe\nrecipe_wf1 &lt;- workflow() %&gt;%\n  add_recipe(recipe_1) %&gt;%\n  add_model(bike_lm)\n\nrecipe_wf2 &lt;- workflow() %&gt;%\n  add_recipe(recipe_2) %&gt;%\n  add_model(bike_lm)\n\nrecipe_wf3 &lt;- workflow() %&gt;%\n  add_recipe(recipe_3) %&gt;%\n  add_model(bike_lm)\n\n# Fitting the models using 10 fold CV via fit_resamples()\nrecipe_fit1 &lt;- recipe_wf1 %&gt;%\n  fit_resamples(cv_folds_10)\n\nrecipe_fit2 &lt;- recipe_wf2 %&gt;%\n  fit_resamples(cv_folds_10)\n\nrecipe_fit3 &lt;- recipe_wf3 %&gt;%\n  fit_resamples(cv_folds_10)\n\n# Binding samples together for best model\nrbind(recipe_fit1 %&gt;% collect_metrics(),\n      recipe_fit2 %&gt;% collect_metrics(),\n      recipe_fit3 %&gt;% collect_metrics())\n\nError in `estimate_tune_results()`:\n! All models failed. Run `show_notes(.Last.tune.result)` for more information.\n\n\n\nAs the final steps we’ll use our best model to fit the model on the entire training data set, compute the RMSE, and obtain the final model.\n\n\n# Assigning the best model\nbest_model &lt;- \n  \n# Using last_fit on full training data\nentire_training &lt;- last_fit(best_model, split = bike_split)\n\nError: object 'best_model' not found\n\n# Check RMSE\nfinal_data &lt;- collect_metrics(entire_training)\n\nError: object 'entire_training' not found\n\nfinal_data\n\nError: object 'final_data' not found\n\nfinal_model_coefficients &lt;- entire_training %&gt;%\n  extract_fit_parsnip() %&gt;%\n  tidy()\n\nError: object 'entire_training' not found\n\nfinal_model_coefficients\n\nError: object 'final_model_coefficients' not found"
  }
]